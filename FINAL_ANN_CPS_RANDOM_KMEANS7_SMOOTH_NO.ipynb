{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:38:59.793870Z",
     "start_time": "2020-12-01T17:38:58.440553Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipynb\n",
    "from ipynb.fs.full.A_libs_26sep import *\n",
    "from ipynb.fs.full.B_funs_26sep import *\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:38:59.813037Z",
     "start_time": "2020-12-01T17:38:59.796315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../results/_FINAL_ANN_CPS_RANDOM_KMEANS7_SMOOTH_NO  Created \n"
     ]
    }
   ],
   "source": [
    "output_dir = create_output_dir()\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:38:59.822356Z",
     "start_time": "2020-12-01T17:38:59.816059Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    num_folds = 10\n",
    "    use_var_enc = True\n",
    "    variance_thres = 0.60\n",
    "    quantile_transform = True\n",
    "    use_rankgauss = True\n",
    "    \n",
    "    selec_top = True\n",
    "    original_feats = True #False remove also top features\n",
    "    \n",
    "    use_pca = True\n",
    "    pca_comp_genes = 29 #30\n",
    "    pca_comp_cells = 4 #18\n",
    "    \n",
    "    use_fastica = False\n",
    "    fastica_comp_genes = 10\n",
    "    fastica_comp_cells = 5\n",
    "    \n",
    "    use_kridge = True\n",
    "    use_kridge_group = False\n",
    "    \n",
    "    use_xgb = False\n",
    "    use_bayes = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataBases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:05.164669Z",
     "start_time": "2020-12-01T17:38:59.824145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 1083)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "train_drug = pd.read_csv('../input/train_drug.csv')\n",
    "\n",
    "drug_dict = dict(zip(train_drug['sig_id'],train_drug['drug_id']))\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\n",
    "\n",
    "train_orig = train_features.merge(train_targets_scored, on='sig_id', how='left')\n",
    "# train_orig = train_orig.merge(train_targets_nonscored, on='sig_id', how='left')\n",
    "train_orig = train_orig.merge(train_drug, on='sig_id', how='left')\n",
    "\n",
    "train_noctl = train_orig[train_orig['cp_type']!='ctl_vehicle'].drop('cp_type', axis=1).reset_index(drop=True)\n",
    "train_ctl = train_orig[train_orig['cp_type']=='ctl_vehicle'].drop('cp_type', axis=1).reset_index(drop=True)\n",
    "\n",
    "test_noctl = test_features[test_features['cp_type']!='ctl_vehicle'].drop('cp_type', axis=1).reset_index(drop=True)\n",
    "test_ctl = test_features[test_features['cp_type']=='ctl_vehicle'].drop('cp_type', axis=1).reset_index(drop=True)\n",
    "\n",
    "target = train_noctl[train_targets_scored.columns]\n",
    "\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "target_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()\n",
    "# target_nonscored_cols = train_targets_nonscored.drop('sig_id', axis=1).columns.values.tolist()\n",
    "other_feats = []\n",
    "\n",
    "\n",
    "# mskf = MultilabelStratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=43)\n",
    "# for f, (t_idx, v_idx) in enumerate(mskf.split(X=train_noctl, y=target)):\n",
    "#     folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "# folds['kfold'] = folds['kfold'].astype(int)\n",
    "# sum_ones = train_noctl[target_cols].sum(axis=0)\n",
    "\n",
    "folds = train_noctl.copy()\n",
    "print(train_orig.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calc Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:05.173514Z",
     "start_time": "2020-12-01T17:39:05.167601Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_folds(seed_fold):\n",
    "    seed_everything(seed=seed_fold)\n",
    "    \n",
    "    folds = train_noctl.copy()\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=seed_fold)\n",
    "    train_noctl['kfold'] = 0.0\n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train_noctl, y=target)):\n",
    "        train_noctl.loc[v_idx, 'kfold'] = int(f)\n",
    "    train_noctl['kfold']  = train_noctl['kfold'].astype('int')\n",
    "    return train_noctl['kfold'].values\n",
    "\n",
    "    \n",
    "#     seed_everything(seed=seed_fold)\n",
    "#     # LOCATE DRUGS\n",
    "#     vc = train_noctl.drug_id.value_counts()\n",
    "#     vc1 = vc.loc[(vc==6)|(vc==12)|(vc==18)].index.sort_values()\n",
    "#     vc2 = vc.loc[(vc!=6)&(vc!=12)&(vc!=18)].index.sort_values()\n",
    "\n",
    "# #     vc1 = vc.loc[vc <= 18].index.sort_values()\n",
    "# #     vc2 = vc.loc[vc > 18].index.sort_values()\n",
    "\n",
    "#      # STRATIFY DRUGS 18X OR LESS\n",
    "#     dct1 = {}; dct2 = {}\n",
    "#     skf = MultilabelStratifiedKFold(n_splits = CFG.num_folds, shuffle = True, random_state = seed_fold)\n",
    "#     # skf = KFold(n_splits = CFG.num_folds, shuffle = True, random_state = 42)\n",
    "#     tmp = train_noctl.groupby('drug_id')[target_cols].mean().loc[vc1]\n",
    "\n",
    "#     for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "#         dd = {k:fold for k in tmp.index[idxV].values}\n",
    "#         dct1.update(dd)\n",
    "\n",
    "#     # STRATIFY DRUGS MORE THAN 18X\n",
    "#     skf = MultilabelStratifiedKFold(n_splits = CFG.num_folds, shuffle = True, random_state = seed_fold)\n",
    "#     # skf = KFold(n_splits = CFG.num_folds, shuffle = True, random_state = 42)\n",
    "#     tmp = train_noctl.loc[train_noctl['drug_id'].isin(vc2)].reset_index(drop = True)\n",
    "#     for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "#         dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "#         dct2.update(dd)\n",
    "    \n",
    "#     # ASSIGN FOLDS\n",
    "#     train_noctl['kfold'] = train_noctl.drug_id.map(dct1)\n",
    "#     train_noctl.loc[train_noctl['kfold'].isna(),'kfold'] = train_noctl.loc[train_noctl['kfold'].isna(),'sig_id'].map(dct2)\n",
    "#     train_noctl['kfold']  = train_noctl['kfold'].astype('int')\n",
    "#     return train_noctl['kfold'].values     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RankGauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:15.118331Z",
     "start_time": "2020-12-01T17:39:05.175225Z"
    }
   },
   "outputs": [],
   "source": [
    "#From: https://www.kaggle.com/kushal1506/moa-pytorch-0-01859-rankgauss-pca-nn\n",
    "folds_cp = folds.copy()\n",
    "test_noctl_cp = test_noctl.copy()\n",
    "\n",
    "if CFG.use_rankgauss:\n",
    "    for col in (GENES + CELLS):\n",
    "        transformer = QuantileTransformer(n_quantiles=100,random_state=42, output_distribution=\"normal\")\n",
    "        vec_len = len(folds_cp[col].values)\n",
    "        vec_len_test = len(test_noctl_cp[col].values)\n",
    "        raw_vec = folds_cp[col].values.reshape(vec_len, 1)\n",
    "        transformer.fit(raw_vec)\n",
    "\n",
    "        folds_cp[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "        test_noctl_cp[col] = transformer.transform(test_noctl_cp[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:23.380469Z",
     "start_time": "2020-12-01T17:39:15.120655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1089) (3624, 882)\n",
      "(21948, 1096) (3624, 889)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import gc\n",
    "\n",
    "def create_cluster(train, test, features, kind = 'g', n_clusters = 35):\n",
    "    train_ = train[features].copy()\n",
    "    test_ = test[features].copy()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_ = scaler.fit_transform(train_)\n",
    "    test_ = scaler.transform(test_)\n",
    "    model = KMeans(n_clusters = n_clusters, random_state = 123).fit(train_)\n",
    "    name_cols = [f'kmeans_{kind}_{i}' for i in range(n_clusters)]\n",
    "    train = pd.concat([train, pd.DataFrame(model.transform(train_), columns=name_cols)], axis=1)\n",
    "    test = pd.concat([test, pd.DataFrame(model.transform(test_), columns=name_cols)], axis=1)\n",
    "    print(train.shape, test.shape)\n",
    "    return train, test\n",
    "    \n",
    "folds_cp2 = folds.copy()\n",
    "test_noctl_cp2 = test_noctl.copy()\n",
    "folds_cp2, test_noctl_cp2 = create_cluster(folds_cp2,test_noctl_cp2, GENES, kind = 'g', n_clusters = 7)\n",
    "folds_cp2, test_noctl_cp2 = create_cluster(folds_cp2,test_noctl_cp2, CELLS, kind = 'c', n_clusters = 7)\n",
    "\n",
    "folds_3models = folds_cp2[list(folds_cp2.columns.values[np.where(folds_cp2.columns=='kmeans_g_0')[0][0]:])]\n",
    "test_noctl_3model = test_noctl_cp2[list(folds_cp2.columns.values[np.where(folds_cp2.columns=='kmeans_g_0')[0][0]:])]\n",
    "del folds_cp2, test_noctl_cp2\n",
    "gc.collect()\n",
    "\n",
    "# train_features ,test_features=fe_cluster(train_features,test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:24.437167Z",
     "start_time": "2020-12-01T17:39:23.381881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1111) (3624, 904)\n",
      "(21948, 1115) (3624, 908)\n"
     ]
    }
   ],
   "source": [
    "if CFG.use_pca:\n",
    "    seed_everything(seed=42)\n",
    "    etiq = ['G','C']\n",
    "    num_pca = [CFG.pca_comp_genes, CFG.pca_comp_cells]\n",
    "    for niter, cols in enumerate([GENES, CELLS]):\n",
    "        # PCA for train with folds\n",
    "        num_comp = num_pca[niter]\n",
    "        columns_pca = [f'pca_{etiq[niter]}-{i}' for i in range(num_comp)]\n",
    "        other_feats += columns_pca\n",
    "\n",
    "        # PCA for train\n",
    "        pca = PCA(n_components=num_comp, random_state=42).fit(folds_cp[cols])\n",
    "        train_pca = pca.transform(folds_cp[cols])\n",
    "        train_pca = pd.DataFrame(train_pca, columns=columns_pca)\n",
    "        folds = pd.concat((folds, train_pca), axis=1)\n",
    "        \n",
    "        # PCA for train\n",
    "        test_pca = pca.transform(test_noctl_cp[cols])\n",
    "        test_pca = pd.DataFrame(test_pca, columns=columns_pca)\n",
    "        test_noctl = pd.concat((test_noctl, test_pca), axis=1)\n",
    "        print(folds.shape, test_noctl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:24.442173Z",
     "start_time": "2020-12-01T17:39:24.438736Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils import check_random_state  # type: ignore\n",
    "\n",
    "# ### from eli5\n",
    "# def iter_shuffled(X, columns_to_shuffle=None, pre_shuffle=False, random_state=None):\n",
    "#     rng = check_random_state(random_state)\n",
    "\n",
    "#     if columns_to_shuffle is None:\n",
    "#         columns_to_shuffle = range(X.shape[1])\n",
    "\n",
    "#     if pre_shuffle:\n",
    "#         X_shuffled = X.copy()\n",
    "#         rng.shuffle(X_shuffled)\n",
    "\n",
    "#     X_res = X.copy()\n",
    "#     for columns in tqdm(columns_to_shuffle):\n",
    "#         if pre_shuffle:\n",
    "#             X_res[:, columns] = X_shuffled[:, columns]\n",
    "#         else:\n",
    "#             rng.shuffle(X_res[:, columns])\n",
    "#         yield X_res\n",
    "#         X_res[:, columns] = X[:, columns]\n",
    "\n",
    "# def get_score_importances(\n",
    "#         score_func,  # type: Callable[[Any, Any], float]\n",
    "#         X,\n",
    "#         y,\n",
    "#         n_iter=5,  # type: int\n",
    "#         columns_to_shuffle=None,\n",
    "#         random_state=None\n",
    "#     ):\n",
    "#     rng = check_random_state(random_state)\n",
    "#     base_score = score_func(X, y)\n",
    "#     scores_decreases = []\n",
    "#     for i in range(n_iter):\n",
    "#         scores_shuffled = _get_scores_shufled(\n",
    "#             score_func, X, y, columns_to_shuffle=columns_to_shuffle,\n",
    "#             random_state=rng, base_score=base_score\n",
    "#         )\n",
    "#         scores_decreases.append(scores_shuffled)\n",
    "\n",
    "#     return base_score, scores_decreases\n",
    "\n",
    "# def _get_scores_shufled(score_func, X, y, base_score, columns_to_shuffle=None,\n",
    "#                         random_state=None):\n",
    "#     Xs = iter_shuffled(X, columns_to_shuffle, random_state=random_state)\n",
    "#     res = []\n",
    "#     for X_shuffled in Xs:\n",
    "#         res.append(-score_func(X_shuffled, y) + base_score)\n",
    "#     return res\n",
    "\n",
    "# def metric(y_true, y_pred):\n",
    "#     metrics = []\n",
    "#     for i in range(y_pred.shape[1]):\n",
    "#         if y_true[:, i].sum() > 1:\n",
    "#             metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float)))\n",
    "#     return np.mean(metrics)   \n",
    "\n",
    "# perm_imp = np.zeros(train.shape[1])\n",
    "# all_res = []\n",
    "# for n, (tr, te) in enumerate(KFold(n_splits=7, random_state=0, shuffle=True).split(train_targets)):\n",
    "#     print(f'Fold {n}')\n",
    "\n",
    "#     model = create_model(len(train.columns))\n",
    "#     checkpoint_path = f'repeat:{seed}_Fold:{n}.hdf5'\n",
    "#     reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n",
    "#     cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n",
    "#                                      save_weights_only = True, mode = 'min')\n",
    "#     model.fit(train.values[tr],\n",
    "#                   train_targets.values[tr],\n",
    "#                   validation_data=(train.values[te], train_targets.values[te]),\n",
    "#                   epochs=35, batch_size=128,\n",
    "#                   callbacks=[reduce_lr_loss, cb_checkpt], verbose=2\n",
    "#                  )\n",
    "        \n",
    "#     model.load_weights(checkpoint_path)\n",
    "        \n",
    "#     def _score(X, y):\n",
    "#         pred = model.predict(X)\n",
    "#         return metric(y, pred)\n",
    "\n",
    "#     base_score, local_imp = get_score_importances(_score, train.values[te], train_targets.values[te], n_iter=1, random_state=0)\n",
    "#     all_res.append(local_imp)\n",
    "#     perm_imp += np.mean(local_imp, axis=0)\n",
    "#     print('')\n",
    "    \n",
    "# top_feats = np.argwhere(perm_imp < 0).flatten()\n",
    "# top_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:24.710084Z",
     "start_time": "2020-12-01T17:39:24.443615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1025) (3624, 819)\n"
     ]
    }
   ],
   "source": [
    "if CFG.selec_top:\n",
    "    seed_everything(seed=42)\n",
    "    # https://www.kaggle.com/simakov/keras-multilabel-neural-network-v1-2/data\n",
    "    top_feats = [  1,   2,   3,   4,   5,   6,   7,   9,  11,  14,  15,  16,  17,\n",
    "            18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
    "            32,  33,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  46,\n",
    "            47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,  60,\n",
    "            61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
    "            74,  75,  76,  78,  79,  80,  81,  82,  83,  84,  86,  87,  88,\n",
    "            89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
    "           102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
    "           115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
    "           129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143,\n",
    "           144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
    "           158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
    "           171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
    "           184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197,\n",
    "           198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212,\n",
    "           213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226,\n",
    "           227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
    "           240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
    "           254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
    "           267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
    "           281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294,\n",
    "           295, 296, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
    "           310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
    "           324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
    "           337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
    "           350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
    "           363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376, 377,\n",
    "           378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391,\n",
    "           392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
    "           405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 416, 417, 418,\n",
    "           419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
    "           432, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446,\n",
    "           447, 448, 449, 450, 453, 454, 456, 457, 458, 459, 460, 461, 462,\n",
    "           463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
    "           476, 477, 478, 479, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
    "           490, 491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 505,\n",
    "           506, 507, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 521,\n",
    "           522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 534, 535, 536,\n",
    "           538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551,\n",
    "           552, 554, 557, 559, 560, 561, 562, 565, 566, 567, 568, 569, 570,\n",
    "           571, 572, 573, 574, 575, 577, 578, 580, 581, 582, 583, 584, 585,\n",
    "           586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 599,\n",
    "           600, 601, 602, 606, 607, 608, 609, 611, 612, 613, 615, 616, 617,\n",
    "           618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,\n",
    "           631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 644,\n",
    "           645, 646, 647, 648, 649, 650, 651, 652, 654, 655, 656, 658, 659,\n",
    "           660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672,\n",
    "           673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
    "           686, 687, 688, 689, 691, 692, 693, 694, 695, 696, 697, 699, 700,\n",
    "           701, 702, 704, 705, 707, 708, 709, 710, 711, 713, 714, 716, 717,\n",
    "           718, 720, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,\n",
    "           733, 734, 735, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747,\n",
    "           748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 759, 760, 761,\n",
    "           762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774,\n",
    "           775, 776, 777, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788,\n",
    "           789, 790, 792, 793, 794, 795, 796, 797, 798, 800, 801, 802, 803,\n",
    "           804, 805, 806, 808, 809, 811, 813, 814, 815, 816, 817, 818, 819,\n",
    "           821, 822, 823, 825, 826, 827, 828, 829, 830, 831, 832, 834, 835,\n",
    "           837, 838, 839, 840, 841, 842, 845, 846, 847, 848, 850, 851, 852,\n",
    "           854, 855, 856, 858, 859, 860, 861, 862, 864, 866, 867, 868, 869,\n",
    "           870, 871, 872, 873, 874]\n",
    "    # print(len(top_feats))\n",
    "    selected_features = np.array(['cp_type','cp_time', 'cp_dose']+GENES+CELLS)[top_feats].tolist()\n",
    "    GENES = [col for col in selected_features if 'g-' in col]\n",
    "    CELLS = [col for col in selected_features if 'c-' in col]\n",
    "    numeric_cols = other_feats + GENES + CELLS\n",
    "    folds = folds[['sig_id','cp_time','cp_dose']+numeric_cols+target_cols]\n",
    "    test_noctl = test_noctl[['sig_id','cp_time','cp_dose']+numeric_cols]\n",
    "    print(folds.shape, test_noctl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Dataset using Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:24.717640Z",
     "start_time": "2020-12-01T17:39:24.711666Z"
    }
   },
   "outputs": [],
   "source": [
    "class VarianceThreshold:\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "    def fit(self, df, cont_cols):\n",
    "        self.cont_cols = cont_cols\n",
    "        self.var = folds[cont_cols].var()\n",
    "        good_cols = self.var[self.var > self.threshold]\n",
    "        self.index = good_cols.index.to_list()\n",
    "        self.dropcols = [x for x in cont_cols if x not in self.var[self.var > self.threshold].index.to_list()]\n",
    "        self.validcols = [x for x in cont_cols if x in self.var[self.var > self.threshold].index.to_list()]\n",
    "    def transform(self, df):\n",
    "        return df.drop(self.dropcols, axis=1)\n",
    "    def fit_transform(self, df, cont_cols):\n",
    "        self.fit(df, cont_cols)\n",
    "        return self.transform(df), self.validcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:26.848024Z",
     "start_time": "2020-12-01T17:39:24.719081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Threshold: 0.6\n",
      "(21948, 1025) (3624, 819)\n",
      "(21948, 1011) (3624, 805)\n"
     ]
    }
   ],
   "source": [
    "if CFG.use_var_enc:\n",
    "    cont_cols_ini = [i for i in test_noctl.columns if i not in ['sig_id', 'cp_time', 'cp_dose']]\n",
    "    print('Variance Threshold:', CFG.variance_thres)\n",
    "    print(folds.shape, test_noctl.shape)\n",
    "    VarThres = VarianceThreshold(CFG.variance_thres)\n",
    "    folds, cont_cols = VarThres.fit_transform(folds, cont_cols_ini)\n",
    "    test_noctl = VarThres.transform(test_noctl)\n",
    "    print(folds.shape, test_noctl.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include kridge features  removing with low num of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:26.851957Z",
     "start_time": "2020-12-01T17:39:26.849552Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_03octe30 = pd.read_csv('../input/res_kridge_03oct_e30_v2.csv')\n",
    "# df_03octe31 = pd.read_csv('../input/res_kridge_03oct_e31_v2.csv')\n",
    "# df_03oct = pd.concat([df_03octe30, df_03octe31], sort=False)\n",
    "# df_03octe30.shape, df_03octe31.shape, df_03oct.shape\n",
    "# df_03oct[df_03oct.sumones>10].AUC.mean()\n",
    "\n",
    "# df_16oct = pd.read_csv('../results/_29_Create_KRIDGE_feats_16oct_e30/res.csv')\n",
    "# df_16oct.head()\n",
    "# df_16oct[df_16oct.sumones>10].AUC.mean()\n",
    "# res_dos = []\n",
    "# for max_ones in range(40):\n",
    "#     res_dos.append(dict(max_ones=max_ones, oct3=df_03oct[df_03oct.sumones>max_ones].AUC.mean(), oct16=df_16oct[df_16oct.sumones>max_ones].AUC.mean()))\n",
    "# res_dos = pd.DataFrame(res_dos)\n",
    "\n",
    "# sns.lineplot(data=res_dos, x='max_ones', y='oct3',label='oct3')\n",
    "# sns.lineplot(data=res_dos, x='max_ones', y='oct16',label='oct16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:32.359953Z",
     "start_time": "2020-12-01T17:39:26.853453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 153 (21948, 1164) (3624, 958)\n"
     ]
    }
   ],
   "source": [
    "if CFG.use_kridge:\n",
    "#     seed_everything(seed=42)\n",
    "#     folds_feat = pd.read_csv('../input/folds_feats.csv')\n",
    "#     test_feat = pd.read_csv('../input/test_feat.csv')\n",
    "#     kridge_cols = ['sig_id']+[col for col in folds_feat if 'kridge' in col]\n",
    "#     folds = pd.merge(folds, folds_feat[kridge_cols], on='sig_id')\n",
    "#     test_noctl = pd.merge(test_noctl, test_feat[kridge_cols], on='sig_id')\n",
    "#     print(folds.shape, test_noctl.shape)\n",
    "    \n",
    "    min_num_ones = 20\n",
    "    folds_feat = pd.read_csv('../results/_29_Create_KRIDGE_feats_16oct_e30/folds.csv')\n",
    "    test_feat = pd.read_csv('../results/_29_Create_KRIDGE_feats_16oct_e30/test.csv')\n",
    "    \n",
    "    colsk = [col.replace('kridge_','') for col in folds_feat if 'kridge' in col]\n",
    "    colsk_selec = []\n",
    "    target_selec = []\n",
    "    for colk in colsk:\n",
    "        if np.sum(folds[colk].sum())>=min_num_ones:\n",
    "            colsk_selec += ['kridge_'+colk]\n",
    "            target_selec += [colk]\n",
    "    kridge_cols = ['sig_id']+colsk_selec\n",
    "\n",
    "    folds = pd.merge(folds, folds_feat[kridge_cols], on='sig_id')\n",
    "    test_noctl = pd.merge(test_noctl, test_feat[kridge_cols], on='sig_id')\n",
    "    print(len(colsk), len(colsk_selec), folds.shape, test_noctl.shape)\n",
    "    \n",
    "    kridge_cols = [col for col in folds if 'kridge_' in col]\n",
    "#     print('logloss=',log_loss_multi(folds[target_selec].values, folds[kridge_cols].values))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:32.369941Z",
     "start_time": "2020-12-01T17:39:32.361641Z"
    }
   },
   "outputs": [],
   "source": [
    "if CFG.use_kridge_group:\n",
    "\n",
    "    colsk_selec = ['kridge_group003', 'kridge_group007', 'kridge_group008', 'kridge_group009', 'kridge_group010', 'kridge_group012', 'kridge_group016', 'kridge_group020', \n",
    "                    'kridge_group025', 'kridge_group028', 'kridge_group029', 'kridge_group035', 'kridge_group036', 'kridge_group039', 'kridge_group049', 'kridge_group051', \n",
    "                    'kridge_group053', 'kridge_group056', 'kridge_group057', 'kridge_group063', 'kridge_group066', 'kridge_group068', 'kridge_group069', 'kridge_group075', \n",
    "                    'kridge_group076', 'kridge_group080', 'kridge_group081', 'kridge_group085', 'kridge_group088', 'kridge_group091', 'kridge_group093', 'kridge_group094', \n",
    "                    'kridge_group095', 'kridge_group098', 'kridge_group099', 'kridge_group100', 'kridge_group101', 'kridge_group103', 'kridge_group105', 'kridge_group106', \n",
    "                    'kridge_group107', 'kridge_group109', 'kridge_group115', 'kridge_group118', 'kridge_group120', 'kridge_group128', 'kridge_group129', 'kridge_group130', \n",
    "                    'kridge_group131', 'kridge_group134', 'kridge_group137', 'kridge_group138', 'kridge_group139', 'kridge_group141', 'kridge_group142', 'kridge_group143', \n",
    "                    'kridge_group144', 'kridge_group150', 'kridge_group152', 'kridge_group153', 'kridge_group154', 'kridge_group155', 'kridge_group156', 'kridge_group158', \n",
    "                    'kridge_group159', 'kridge_group162', 'kridge_group163', 'kridge_group165', 'kridge_group168', 'kridge_group173', 'kridge_group174', 'kridge_group175', \n",
    "                    'kridge_group176', 'kridge_group177', 'kridge_group178', 'kridge_group182', 'kridge_group184', 'kridge_group186', 'kridge_group187', 'kridge_group191', \n",
    "                    'kridge_group192', 'kridge_group193', 'kridge_group198', 'kridge_group199', 'kridge_group201', 'kridge_group202', 'kridge_group206', 'kridge_group208', \n",
    "                    'kridge_group209', 'kridge_group211', 'kridge_group213', 'kridge_group215', 'kridge_group216', 'kridge_group219', 'kridge_group220', 'kridge_group221', \n",
    "                    'kridge_group224', 'kridge_group225', 'kridge_group227', 'kridge_group229', 'kridge_group233', 'kridge_group234', 'kridge_group235', 'kridge_group236', \n",
    "                    'kridge_group238', 'kridge_group240', 'kridge_group243', 'kridge_group244', 'kridge_group246', 'kridge_group247', 'kridge_group249', 'kridge_group255', \n",
    "                    'kridge_group256', 'kridge_group257', 'kridge_group262', 'kridge_group263', 'kridge_group265', 'kridge_group266', 'kridge_group268', 'kridge_group269', \n",
    "                    'kridge_group271', 'kridge_group272', 'kridge_group273', 'kridge_group274', 'kridge_group276', 'kridge_group278', 'kridge_group284', 'kridge_group286', \n",
    "                    'kridge_group287', 'kridge_group288', 'kridge_group289', 'kridge_group291', 'kridge_group292', 'kridge_group293', 'kridge_group294', 'kridge_group298', \n",
    "                    'kridge_group301', 'kridge_group304', 'kridge_group305', 'kridge_group306', 'kridge_group307', 'kridge_group308', 'kridge_group311', 'kridge_group314', \n",
    "                    'kridge_group316', 'kridge_group317', 'kridge_group320', 'kridge_group323', 'kridge_group324', 'kridge_group325']\n",
    "    \n",
    "    folds_feat = pd.read_csv('../results/_2004_Create_KRIDGE_groupedbytargets/folds.csv')\n",
    "    test_feat = pd.read_csv('../results/_2004_Create_KRIDGE_groupedbytargets/test.csv')\n",
    "    \n",
    "    kridge_cols = ['sig_id']+colsk_selec\n",
    "    folds = pd.merge(folds, folds_feat[kridge_cols], on='sig_id')\n",
    "    test_noctl = pd.merge(test_noctl, test_feat[kridge_cols], on='sig_id')\n",
    "    print(len(colsk), len(colsk_selec), folds.shape, test_noctl.shape)\n",
    "\n",
    "    kridge_cols = [col for col in folds if 'kridge_' in col]\n",
    "    print(len(kridge_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include XGB features removing with low num of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:32.401523Z",
     "start_time": "2020-12-01T17:39:32.371456Z"
    }
   },
   "outputs": [],
   "source": [
    "if CFG.use_xgb:\n",
    "#     seed_everything(seed=42)\n",
    "#     folds_feat = pd.read_csv('../input/folds_feats.csv')\n",
    "#     test_feat = pd.read_csv('../input/test_feat.csv')\n",
    "#     kridge_cols = ['sig_id']+[col for col in folds_feat if 'kridge' in col]\n",
    "#     folds = pd.merge(folds, folds_feat[kridge_cols], on='sig_id')\n",
    "#     test_noctl = pd.merge(test_noctl, test_feat[kridge_cols], on='sig_id')\n",
    "#     print(folds.shape, test_noctl.shape)\n",
    "    min_num_ones = 25\n",
    "\n",
    "    dir_model = '_31_model_XGB_withkridge_5oct_v2'\n",
    "    dir_res = '../results/' + dir_model + '/'\n",
    "    name_file = [i for i in os.listdir(dir_res) if 'dataframe' in i][0]\n",
    "    with open(dir_res + name_file, 'rb') as file:\n",
    "        folds_feat = pickle.load(file)\n",
    "        test_feat = pickle.load(file)\n",
    "        xbg_y_true = pickle.load(file)\n",
    "        xgb_y_pred = pickle.load(file)\n",
    "        xgb_feature_cols = pickle.load(file)\n",
    "        xgb_target_cols = pickle.load(file)\n",
    "    \n",
    "    cols_xgb = xgb_target_cols\n",
    "    cols_xgb_selec = []\n",
    "    for colx in cols_xgb:\n",
    "        if np.sum(folds[colx].sum())>=min_num_ones:\n",
    "            cols_xgb_selec += [colx]\n",
    "    print(len(cols_xgb_selec))\n",
    "    \n",
    "    folds_feat_selec = folds_feat[['sig_id'] + cols_xgb_selec]\n",
    "    test_noctl_selec = test_feat[['sig_id'] + cols_xgb_selec]\n",
    "    new_colnames  = ['xgb_'+i for i in cols_xgb_selec]\n",
    "    folds_feat_selec.columns = ['sig_id'] +new_colnames\n",
    "    test_noctl_selec.columns = ['sig_id'] +new_colnames\n",
    "\n",
    "    folds = pd.merge(folds, folds_feat_selec[['sig_id'] + new_colnames], on='sig_id')\n",
    "    test_noctl = pd.merge(test_noctl, test_noctl_selec[['sig_id'] + new_colnames], on='sig_id')\n",
    "    print(folds.shape, test_noctl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include features bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:32.426680Z",
     "start_time": "2020-12-01T17:39:32.403641Z"
    }
   },
   "outputs": [],
   "source": [
    "if CFG.use_bayes:\n",
    "#     seed_everything(seed=42)\n",
    "#     folds_feat = pd.read_csv('../input/folds_feats.csv')\n",
    "#     test_feat = pd.read_csv('../input/test_feat.csv')\n",
    "#     kridge_cols = ['sig_id']+[col for col in folds_feat if 'kridge' in col]\n",
    "#     folds = pd.merge(folds, folds_feat[kridge_cols], on='sig_id')\n",
    "#     test_noctl = pd.merge(test_noctl, test_feat[kridge_cols], on='sig_id')\n",
    "#     print(folds.shape, test_noctl.shape)\n",
    "    \n",
    "    folds_feat = pd.read_csv('../input/bayes_folds_feats30sep_e30.csv')\n",
    "    test_feat = pd.read_csv('../input/bayes_test_feats30sep_e30.csv')\n",
    "    bayes_cols = ['sig_id']+[col for col in folds_feat if 'bayes' in col]\n",
    "    folds = pd.merge(folds, folds_feat[bayes_cols], on='sig_id')\n",
    "    test_noctl = pd.merge(test_noctl, test_feat[bayes_cols], on='sig_id')\n",
    "    \n",
    "    folds_feat = pd.read_csv('../input/bayes_folds_feats30sep_e31.csv')\n",
    "    test_feat = pd.read_csv('../input/bayes_test_feats30sep_e31.csv')\n",
    "    bayes_cols = ['sig_id']+[col for col in folds_feat if 'bayes' in col]\n",
    "    folds = pd.merge(folds, folds_feat[bayes_cols], on='sig_id')\n",
    "    test_noctl = pd.merge(test_noctl, test_feat[bayes_cols], on='sig_id')\n",
    "\n",
    "    print(folds.shape, test_noctl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Transform of Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:43.711375Z",
     "start_time": "2020-12-01T17:39:32.428817Z"
    }
   },
   "outputs": [],
   "source": [
    "if CFG.quantile_transform:\n",
    "    qt = QuantileTransformer(output_distribution='normal')\n",
    "    folds[cont_cols] = qt.fit_transform(folds[cont_cols])\n",
    "    test_noctl[cont_cols] = qt.transform(test_noctl[cont_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low or High 0.05 and 0.95 percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:43.715983Z",
     "start_time": "2020-12-01T17:39:43.713567Z"
    }
   },
   "outputs": [],
   "source": [
    "# var_thresh = VarianceThreshold(threshold=0.7)\n",
    "# data = train_features.append(test_features)\n",
    "# data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "# train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "# test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "# train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "#                               columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "# train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "# test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "#                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "# test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "# train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:43.746927Z",
     "start_time": "2020-12-01T17:39:43.717548Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_noctl_inicial = train_orig[train_orig['cp_type']!='ctl_vehicle'].drop('cp_type', axis=1).reset_index(drop=True)\n",
    "# test_noctl_inicial = test_features[test_features['cp_type']!='ctl_vehicle'].drop('cp_type', axis=1).reset_index(drop=True)\n",
    "\n",
    "# folds['menos10_genes'] = (train_noctl_inicial[GENES]== -10.0).mean(axis=1)\n",
    "# folds['menos10_cells'] = (train_noctl_inicial[CELLS]== -10.0).mean(axis=1)\n",
    "\n",
    "# test_noctl['menos10_genes'] = (test_noctl_inicial[GENES]== -10.0).mean(axis=1)\n",
    "# test_noctl['menos10_cells'] = (test_noctl_inicial[CELLS]== -10.0).mean(axis=1)\n",
    "# print(folds.shape, test_noctl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:43.943558Z",
     "start_time": "2020-12-01T17:39:43.748845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1178) (3624, 972)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = pd.concat((folds, folds_3models), axis=1)\n",
    "test_noctl = pd.concat((test_noctl, test_noctl_3model), axis=1)\n",
    "print(folds.shape, test_noctl.shape)\n",
    "del folds_3models, test_noctl_3model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:43.947976Z",
     "start_time": "2020-12-01T17:39:43.945184Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:44.325026Z",
     "start_time": "2020-12-01T17:39:43.949435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = process_data(folds)\n",
    "test_noctl = process_data(test_noctl)\n",
    "\n",
    "feature_cols = [c for c in folds.columns if c not in target_cols]\n",
    "if not CFG.original_feats: feature_cols = [c for c in feature_cols if c not in GENES+CELLS]\n",
    "feature_cols_ini = [c for c in feature_cols if c not in ['kfold','sig_id']] #, 'cp_time_24', 'cp_time_48', 'cp_time_72', 'cp_dose_D1', 'cp_dose_D2']] #,'cp_dose','cp_time']]\n",
    "len(feature_cols_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:45.277132Z",
     "start_time": "2020-12-01T17:39:44.326543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca_G-0 -3.165934989350809e-05 1.000022942477717\n",
      "pca_G-1 2.3190635233523497e-05 0.999589967313473\n",
      "pca_G-2 -5.6528317499562846e-05 0.9998962469475889\n",
      "pca_G-3 0.00014903320099432797 1.0001572798115808\n",
      "pca_G-4 3.974275730476318e-05 0.9997665499591254\n",
      "pca_G-5 7.361036404475456e-05 0.9997785695567266\n",
      "pca_G-6 -3.722530770049402e-05 0.9997154816867923\n",
      "pca_G-7 -4.176801412068981e-05 1.000241038168113\n",
      "pca_G-8 -3.368941635777072e-05 0.9998038447404773\n",
      "pca_G-9 5.6154809742764314e-05 0.9997265629134641\n",
      "pca_G-10 -9.040019011965188e-05 0.9996772931738684\n",
      "pca_G-11 -6.0787953075223735e-05 0.9997559892025474\n",
      "pca_G-12 -5.8613588758092277e-05 0.9994258399589677\n",
      "pca_G-13 -9.893185187019985e-05 0.9997849369040595\n",
      "pca_G-14 -6.201536405677035e-05 0.9997168847993001\n",
      "pca_G-15 -8.278464554952898e-05 0.9994982924307781\n",
      "pca_G-16 -3.833382519051168e-06 1.0007720562770315\n",
      "pca_G-17 -1.2060393554331708e-05 0.9995915837385395\n",
      "pca_G-18 -6.393268281042678e-05 1.0000080139572305\n",
      "pca_G-19 4.308745677184569e-05 0.9999375282232519\n",
      "pca_G-20 1.7704523146213414e-05 0.9999570958275728\n",
      "pca_G-21 -8.041781143949073e-05 0.9999804331381219\n",
      "pca_G-22 -5.485857327712377e-05 0.9995079062061675\n",
      "pca_G-23 -5.548156977200643e-05 0.9999853361194306\n",
      "pca_G-24 -2.8665351269806734e-05 0.999962216956135\n",
      "pca_G-25 4.8121496384403276e-05 0.9999803933858662\n",
      "pca_G-26 -0.00010797373222823576 0.999852890295265\n",
      "pca_G-27 1.1238177298903667e-06 0.999436706774796\n",
      "pca_G-28 2.7147614120910017e-07 0.9997151236893629\n",
      "pca_C-0 -4.622811888497181e-05 0.9998971013558382\n",
      "pca_C-1 -2.4489414777963768e-05 0.999572086213283\n",
      "pca_C-2 8.463152331758097e-05 0.999932478344549\n",
      "pca_C-3 -6.815162067325555e-05 1.0000539666795314\n",
      "g-0 0.0010856840847241374 1.0053220657129336\n",
      "g-1 -9.277820775970884e-05 1.000071001417792\n",
      "g-2 1.870428083275578e-05 0.9996307098585744\n",
      "g-3 -6.743828774588668e-06 1.000304307927906\n",
      "g-4 -0.00011262560407790162 0.9998436207945154\n",
      "g-6 6.471265619678452e-05 0.9995006551305287\n",
      "g-8 -0.011403304405636175 1.0445484320125424\n",
      "g-11 0.0001961747023225419 1.0009660114183692\n",
      "g-12 0.0002842104596479016 1.0008482393765796\n",
      "g-13 0.0015180329256341124 1.006389983269425\n",
      "g-14 -0.00037747159866311896 1.0019571802699656\n",
      "g-16 -0.0007190261635998846 1.002551338203055\n",
      "g-17 -0.0007079417796940588 1.002295967144567\n",
      "g-19 0.00010174843695813431 0.9998053548037309\n",
      "g-20 -0.00037477357653301947 1.0010816447682198\n",
      "g-21 2.3587022735505027e-05 0.9995912574206381\n",
      "g-22 8.696281549299983e-05 0.9998808161558901\n",
      "g-24 -0.0006756881163977918 1.0019179750409806\n",
      "g-26 -8.224523594409243e-05 0.9994860100835429\n",
      "g-27 -3.060099877633643e-05 0.999495146495556\n",
      "g-28 -4.263828430815671e-05 0.9995110498959296\n",
      "g-29 -3.65379557327136e-05 1.0005094929002283\n",
      "g-30 -0.00046745034274186555 1.0010483219418729\n",
      "g-32 -3.0315826365312747e-05 0.9997077635992525\n",
      "g-33 0.0005630549861009437 1.001692972074615\n",
      "g-34 0.001000606409649143 1.0033835095704036\n",
      "g-35 0.00011939699874578661 0.9998846675951207\n",
      "g-36 -0.0016049315402136164 1.0063484826096036\n",
      "g-37 -0.04229189852614354 1.1494492525518762\n",
      "g-38 0.029672702399398048 1.1081188838841267\n",
      "g-39 7.642194038556853e-05 0.9996106005727056\n",
      "g-40 -0.0019900857166518598 1.0081602977828834\n",
      "g-41 -0.0001047206531035147 1.0003455626307733\n",
      "g-43 0.0002830996256156844 1.0013046611243137\n",
      "g-44 1.7655779362868488e-05 0.9996377053284484\n",
      "g-45 -0.00014802394876134938 0.9998500445403651\n",
      "g-46 0.00317478667389809 1.0134084811174775\n",
      "g-47 5.764889397374842e-06 0.9998075604923247\n",
      "g-48 0.0017587464838719135 1.0070580075306623\n",
      "g-49 0.0002668705194959271 1.000545154232074\n",
      "g-50 -0.04788654617065789 1.1668562314051318\n",
      "g-51 6.694826431515453e-05 0.9999402813420075\n",
      "g-52 0.00015685792402927767 1.000266590978425\n",
      "g-53 0.0005305498604109714 1.002350463076067\n",
      "g-55 -0.0016375468134878118 1.0061107936854048\n",
      "g-56 -0.0007056709479265914 1.0022791676168508\n",
      "g-57 0.0014332241386355096 1.0067898338926113\n",
      "g-58 -0.020400310850086232 1.0764466093861662\n",
      "g-59 -0.000843240085739643 1.0037206290165925\n",
      "g-60 -3.124835276506994e-05 0.9993669334003209\n",
      "g-61 -0.0008758470537922545 1.0032478118693073\n",
      "g-62 -0.0060265607484797385 1.0240609833718686\n",
      "g-63 -0.007013261650213163 1.0278491730925832\n",
      "g-64 -4.512015122799767e-05 0.9994005553313573\n",
      "g-65 0.000650514722757141 1.0021489847046487\n",
      "g-66 4.4002447508597585e-05 0.9994001333066097\n",
      "g-67 -0.0582401878296116 1.1984533241212991\n",
      "g-68 0.00019236402727461292 1.0002964103424896\n",
      "g-69 0.00011084278050651603 0.9995541417142952\n",
      "g-70 -0.00014962180074589728 0.9999653125292162\n",
      "g-71 2.7472271302442193e-05 0.999692478561705\n",
      "g-72 -0.016730579654090683 1.0642939108171057\n",
      "g-73 -3.479065307940459e-05 0.9998231279442537\n",
      "g-75 -0.046891146713930125 1.1638544694858486\n",
      "g-76 9.119759576756511e-05 0.9992947715237521\n",
      "g-77 -2.786652522099436e-05 0.999912797251454\n",
      "g-78 7.355126293737198e-05 0.9999740850115219\n",
      "g-79 -6.261453226069835e-06 0.9994825278680407\n",
      "g-80 -8.610831821143288e-05 0.9998336441061584\n",
      "g-81 9.464916197524829e-05 0.9999792141628024\n",
      "g-83 0.0003078093026542147 1.0012011706168724\n",
      "g-84 -2.8503078366341273e-05 0.9997557408071786\n",
      "g-85 0.00011171679497606717 0.9998442904729642\n",
      "g-86 0.005534960354342711 1.0215932658782625\n",
      "g-87 0.00010201238253429359 1.0001826265954856\n",
      "g-88 0.0003502058777455489 1.0004775429596844\n",
      "g-89 4.9251903009597415e-05 0.9994004760705005\n",
      "g-90 0.000345968834606953 1.000539214263172\n",
      "g-91 0.0031553309822552286 1.0126860851271955\n",
      "g-92 3.9267940539615756e-05 0.9996543220078714\n",
      "g-93 0.00031884937817752094 1.000991525909543\n",
      "g-94 2.8334574827492127e-06 0.9993255574611908\n",
      "g-95 0.0002384812033239887 1.0008715698702229\n",
      "g-96 -0.0034735075231412615 1.0137362209118126\n",
      "g-97 0.004869180718094366 1.0191649742184181\n",
      "g-98 -0.003166341254543079 1.0123775546344933\n",
      "g-99 9.235096567171328e-06 0.9995208664289419\n",
      "g-100 0.013323393542922023 1.0508809515862862\n",
      "g-101 -4.215131751458992e-06 0.9994209213366492\n",
      "g-102 0.0010647875568484096 1.0041192238227594\n",
      "g-103 1.1720392395340204e-05 1.0001158839406463\n",
      "g-105 9.736168477250882e-05 0.9994666638699105\n",
      "g-106 0.0031782457464485728 1.012531101707252\n",
      "g-107 9.282501821053541e-05 1.000253888164456\n",
      "g-108 6.759460232761108e-05 0.9996644411568933\n",
      "g-109 0.00017256130201848637 1.0001150115562458\n",
      "g-110 -0.00013794362144140578 1.0004028861088827\n",
      "g-111 0.000797970441279844 1.0027509605150953\n",
      "g-112 -0.0003003081094234059 1.000717405413546\n",
      "g-113 -0.016796658885664766 1.0641758727305632\n",
      "g-114 8.056324977194203e-05 1.0000887624117683\n",
      "g-115 6.646922510192416e-05 0.9999652538342313\n",
      "g-117 0.00026721341569538787 1.0011991621298604\n",
      "g-118 -6.438587961776273e-06 0.9995854427368738\n",
      "g-119 -5.5615478969907615e-05 0.9995825755829153\n",
      "g-120 3.38776968537411e-05 0.9994342757934891\n",
      "g-121 -0.0029099441618257293 1.011736753910446\n",
      "g-122 -4.938543638532895e-07 0.999350152695265\n",
      "g-123 0.025968048683746376 1.0956308562300787\n",
      "g-124 8.86944650514474e-06 0.9994664743127173\n",
      "g-125 3.648801004871146e-05 0.9994742710302168\n",
      "g-126 0.0012306780256100599 1.0047458972739265\n",
      "g-127 8.086669717195677e-05 0.9993799967628639\n",
      "g-128 -0.015487283076513933 1.0599039933323005\n",
      "g-129 7.908404247730615e-05 0.9995557850527161\n",
      "g-130 0.004059604949360723 1.0160369147196413\n",
      "g-133 -5.358702891297025e-05 1.0057211668213502\n",
      "g-134 0.00020647339861691957 1.0002022538054365\n",
      "g-135 0.00012052006941045475 0.9999331057396923\n",
      "g-136 0.00023625691717269856 1.000472073894955\n",
      "g-137 -4.692439931591635e-06 0.9997132981333372\n",
      "g-138 -0.00029156523050832405 1.0026937513107232\n",
      "g-139 0.0008794221079788842 1.002973998091867\n",
      "g-140 3.298870280189798e-05 1.000044392776022\n",
      "g-141 2.005498762414164e-06 0.9996183977611525\n",
      "g-142 0.001160789615751812 1.0049336381958376\n",
      "g-143 -6.823090426450914e-05 0.999890784899179\n",
      "g-144 0.0036070013812506928 1.0142115068692281\n",
      "g-146 0.0018613055317740657 1.0080051191101327\n",
      "g-147 0.005773155580427365 1.0231528989385008\n",
      "g-148 0.0016832962826859748 1.0066668778889463\n",
      "g-149 -0.00010387416645374212 0.9998517344174879\n",
      "g-150 -9.688760551834485e-05 0.9997128766624496\n",
      "g-151 -5.163287673454723e-05 0.9993718475200601\n",
      "g-152 -0.004434531994674995 1.0173887847958123\n",
      "g-154 -8.392016991726123e-05 1.000774988925209\n",
      "g-155 0.002901143623529897 1.0120907353893887\n",
      "g-156 -6.39056106440837e-06 0.9995205584759289\n",
      "g-157 0.00026111526543776175 1.0003025964652994\n",
      "g-158 0.020868328981763568 1.078353586478225\n",
      "g-159 6.957883479297214e-05 0.9998113788950226\n",
      "g-160 -0.001230885426992516 1.0045745331044627\n",
      "g-161 -0.0003909731110172782 1.0014051424288488\n",
      "g-162 2.9652564887606208e-05 0.9994707656952833\n",
      "g-163 0.0052172982961836084 1.0210378301739103\n",
      "g-164 0.003472997798357876 1.0135250819447172\n",
      "g-165 -4.561704414670081e-05 0.9995182061173319\n",
      "g-166 -0.0002522156432084023 1.0004342382288247\n",
      "g-167 2.8284783804481296e-05 0.9997784149746936\n",
      "g-168 0.0001629196276407496 1.0004874093487492\n",
      "g-169 0.0002629623968822474 1.000606228926152\n",
      "g-170 0.006747635154014747 1.0270899147293622\n",
      "g-171 0.0003436528781872168 1.0005130354352583\n",
      "g-172 -0.00012235029428508016 1.0006371195437436\n",
      "g-173 2.6992162657032383e-05 0.9999788171004688\n",
      "g-174 -0.00013087246448437347 0.999945057398805\n",
      "g-175 -3.9067732330446444e-05 1.000020131573068\n",
      "g-176 -0.00017328139505793494 0.9999286642281758\n",
      "g-177 0.001410422249935155 1.0061868232288202\n",
      "g-178 -0.008087793412978888 1.0449888794697642\n",
      "g-179 -5.029253057939618e-05 0.9993806272350073\n",
      "g-180 3.945865184751963e-05 0.99929262340729\n",
      "g-181 0.0011882434368988596 1.0054248087707789\n",
      "g-182 0.00020221811195915461 1.000032650551435\n",
      "g-183 -0.003474393767338591 1.014353631736765\n",
      "g-185 -0.019374370877587328 1.072806690378079\n",
      "g-186 -0.0005919838314349526 1.002026747685688\n",
      "g-187 0.00011889047820751423 0.9996323166799992\n",
      "g-188 0.00013862502092864613 0.9996672712327398\n",
      "g-189 -0.0023595614240339803 1.0108570904065237\n",
      "g-190 2.377338507918543e-06 0.999687941368727\n",
      "g-191 -1.8469638225974083e-05 0.9997880710365935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g-192 0.00010064893766004415 0.9999783274804145\n",
      "g-194 -0.00018718787945757798 1.0006105055574819\n",
      "g-195 -0.013852815983566531 1.0532927617389494\n",
      "g-196 -0.0006110470286010054 1.0015185249210554\n",
      "g-197 0.0035337059096291912 1.013584532484019\n",
      "g-199 -0.00012132593180523838 0.9999246631925712\n",
      "g-200 -5.390627061139611e-05 0.999744241665109\n",
      "g-201 0.010318955831430719 1.0400095166891867\n",
      "g-202 -0.011705118187446958 1.0452692045182317\n",
      "g-203 0.00015822317058976405 0.9998033941910466\n",
      "g-205 -2.0336886546779832e-05 0.9993481599633784\n",
      "g-206 -5.2236448396437755e-06 0.9993807051468245\n",
      "g-207 -6.42168030457151e-05 0.9996756956232318\n",
      "g-208 0.011885103957316704 1.0471444675514614\n",
      "g-209 0.00014482179215395745 1.0002940892778733\n",
      "g-210 0.0008783337807099783 1.002825444749206\n",
      "g-211 6.391463749276528e-05 0.9996842489804277\n",
      "g-212 9.224765209031916e-05 0.9996428538182857\n",
      "g-213 -0.0002921543950907238 1.0069009975519547\n",
      "g-214 -0.0001804455615557744 0.9997551990463769\n",
      "g-215 0.003087975648939873 1.0129114210697607\n",
      "g-217 0.000602635102418152 1.0019229256208246\n",
      "g-218 8.070329132220592e-05 1.0003132064380595\n",
      "g-220 0.0005206479322687917 1.0013850920464693\n",
      "g-221 0.0001512341237971588 0.999803552883958\n",
      "g-222 3.386583980062608e-05 0.9995942937252232\n",
      "g-223 5.117170907299554e-05 0.9998056734078712\n",
      "g-224 0.00013026484886814637 1.0002738202156654\n",
      "g-225 9.159687291055491e-05 0.9998949257479143\n",
      "g-226 0.005975771390920721 1.0242010576410914\n",
      "g-227 -5.436600152316314e-05 0.9997489172276043\n",
      "g-228 -0.07053023931896793 1.2339359551528015\n",
      "g-229 0.00018242654506448253 1.0014103094001108\n",
      "g-230 -8.857295171586114e-06 0.9997474183674196\n",
      "g-231 -0.0014161978396154786 1.0084025409454305\n",
      "g-232 0.0009594765627547391 1.003085047938825\n",
      "g-233 6.794113434663655e-06 0.9996609219778191\n",
      "g-234 -0.0007301118061879706 1.0023102804998032\n",
      "g-235 0.0013796868273937483 1.0053506177677012\n",
      "g-236 6.342416031103277e-05 0.999653482383446\n",
      "g-237 5.347518003569064e-05 0.999846164483604\n",
      "g-239 -0.000707976651539762 1.002449554302606\n",
      "g-240 -5.94645945391285e-05 0.9994815146581919\n",
      "g-241 -1.1669951241427181e-05 1.0006121772951428\n",
      "g-242 0.00018647943436079787 1.0000842372794654\n",
      "g-243 0.0028526861649098593 1.011365936770313\n",
      "g-244 0.0010668685461170332 1.00371576167664\n",
      "g-245 0.0008615490166291545 1.0041132899570309\n",
      "g-246 -9.603245502479327e-05 0.9994022701259614\n",
      "g-247 5.4306772723675944e-05 0.999654259072547\n",
      "g-248 0.022437351933455557 1.0836072490671116\n",
      "g-249 0.0008810509667273127 1.0035499425972252\n",
      "g-250 -0.0082525993230229 1.0319433672585148\n",
      "g-251 0.0032714497685269314 1.0129134626890097\n",
      "g-252 -0.00029023884335977086 1.0007025631163022\n",
      "g-253 -4.327941817463055e-05 0.9999249012936968\n",
      "g-254 0.0005814167988832864 1.001379743479954\n",
      "g-255 -2.8525628288827034e-05 0.9997904563258775\n",
      "g-256 5.923389939493955e-05 0.9997046975533365\n",
      "g-257 -0.008979425621929913 1.0351627194390682\n",
      "g-258 -3.434386586522635e-05 1.0002265577063092\n",
      "g-259 0.0042916702120582104 1.0170692211654415\n",
      "g-260 -2.2031021906578737e-05 0.9994025404677448\n",
      "g-261 0.008692383121523895 1.03375259712838\n",
      "g-262 -0.0001094125836054775 0.9995777904382646\n",
      "g-263 0.0005615771177902724 1.00163158083855\n",
      "g-264 0.003155134918078895 1.0141121028759676\n",
      "g-265 1.2724489246886146e-06 0.9998776675304919\n",
      "g-266 0.002712225189862549 1.0110027765038243\n",
      "g-268 -9.654675140817036e-06 0.9996580204346418\n",
      "g-269 2.9223085651713103e-05 0.9995866583847739\n",
      "g-270 0.014380680966700017 1.0557621586064112\n",
      "g-271 -0.0009680861558384219 1.0033142698939366\n",
      "g-272 -0.0008291038175720221 1.002800078593067\n",
      "g-273 8.533620124453553e-05 0.9996744145723591\n",
      "g-274 0.00014736707839960305 0.9995925252433048\n",
      "g-275 -0.00015277835081961523 1.0000739695999084\n",
      "g-276 -0.0006557949344621804 1.0019662200769188\n",
      "g-277 -3.981898261366737e-05 0.9995070549980107\n",
      "g-278 2.9161879856708644e-05 0.9996877812299574\n",
      "g-279 7.560401111037593e-05 0.9996394954467505\n",
      "g-280 -2.648731916184922e-05 1.000013495437661\n",
      "g-281 -0.0003311067818042026 1.0013453190578827\n",
      "g-282 7.714941917663853e-05 0.999542795058577\n",
      "g-283 -1.2550048464995538e-06 0.99940213587705\n",
      "g-284 4.916604308394578e-05 0.9996872810254137\n",
      "g-285 -3.7474257825070295e-05 0.9995845282065474\n",
      "g-286 6.392894446979533e-05 0.9995662980595516\n",
      "g-287 -9.566318196287805e-06 0.9994515402004863\n",
      "g-288 1.2329694082772764e-05 0.9993721676594493\n",
      "g-289 0.000584954557941153 1.0015568854865793\n",
      "g-291 -0.00401262742893555 1.016359632035133\n",
      "g-292 0.00011906947899355499 0.9993651693676407\n",
      "g-293 -5.3226006935209604e-05 0.9998864545476072\n",
      "g-295 0.0006495238595955457 1.0022247290657258\n",
      "g-297 0.00020066263287311066 1.0009928479444525\n",
      "g-298 -0.0036727829217132334 1.0145447819641213\n",
      "g-299 -0.00020927321724633138 1.0007979414077852\n",
      "g-300 0.0010462904681200732 1.037071350299664\n",
      "g-301 -0.0001252834322541869 0.999741683274226\n",
      "g-302 4.530570333326828e-05 0.9994108382407803\n",
      "g-303 2.9033004605797912e-05 0.9996050183750633\n",
      "g-304 -0.0004888240720097249 1.0014320779767978\n",
      "g-305 6.455995806287291e-05 0.9999589901750734\n",
      "g-306 -0.0009535643939246406 1.0039362229247724\n",
      "g-308 0.001406682655653368 1.0061125432927465\n",
      "g-309 5.293906122206065e-06 0.9994311681796135\n",
      "g-311 7.372780988721356e-05 0.9996348993260218\n",
      "g-312 0.00011445317217758985 1.0001349057553774\n",
      "g-313 2.2312364053472735e-06 0.9996513076153787\n",
      "g-314 -0.0003184291353777989 1.000365234432352\n",
      "g-315 -0.00015740317678363276 1.0001642841884515\n",
      "g-316 -6.822280890138964e-05 1.000212314763275\n",
      "g-317 0.001490298033116478 1.005741481672964\n",
      "g-318 -3.3171467518295776e-05 0.9993828182492148\n",
      "g-319 0.000772316150350661 1.002501287050322\n",
      "g-320 0.0002769056225413036 1.0003523887752965\n",
      "g-321 -0.0003553272435718142 1.001457246357642\n",
      "g-322 4.2535816989171754e-05 0.999891020342755\n",
      "g-323 -8.142614490053337e-07 0.9994201592877662\n",
      "g-324 -3.432208101855812e-05 0.9998404774940016\n",
      "g-325 7.195096427912297e-06 0.9994907266387946\n",
      "g-326 8.110567361788739e-05 0.9994509300714407\n",
      "g-327 -0.0015439894747857792 1.005832842008127\n",
      "g-328 0.034976259835646256 1.126193323910819\n",
      "g-329 -0.0003914260668121301 1.0010929139151965\n",
      "g-330 0.0001057816272136442 0.9997524605946985\n",
      "g-332 -0.008893507280506932 1.0354001293472803\n",
      "g-333 0.0007186859787208428 1.0029922288834205\n",
      "g-334 0.005049234316711668 1.020019584095348\n",
      "g-335 7.81283807029421e-05 0.9998826827633236\n",
      "g-336 0.0005393306246223805 1.0022218679529697\n",
      "g-337 0.0010266407284247924 1.0034928937371235\n",
      "g-338 0.001647341741478239 1.0088446639559445\n",
      "g-339 -0.0001498999052254011 0.9997077681716772\n",
      "g-340 -2.8690512018190153e-05 0.9998233743226782\n",
      "g-341 -7.726917988975683e-05 1.0000239515921856\n",
      "g-342 0.00010482590201385753 1.001653535930268\n",
      "g-343 0.00021782431324667592 1.0009175681930327\n",
      "g-344 0.000838409410188903 1.0040121618128581\n",
      "g-345 -2.2891266857884906e-05 0.9995048340953253\n",
      "g-346 -4.9687613079101646e-05 0.9995761342799505\n",
      "g-347 5.868634474142987e-05 1.0001849404060055\n",
      "g-348 0.0008765350412267515 1.00367300004093\n",
      "g-349 0.011836534249555967 1.0465032970460915\n",
      "g-350 6.51038424009514e-05 0.9996183697117251\n",
      "g-351 0.00012112067747259536 0.9996881590326961\n",
      "g-352 0.00024072454771726254 1.0012283481582094\n",
      "g-353 -0.00690668046178414 1.0273215522441645\n",
      "g-354 3.2526932709420135e-05 0.9996528677918999\n",
      "g-355 -2.0936761223858962e-05 0.9996379517290467\n",
      "g-356 1.21527134901138e-06 0.999486417141116\n",
      "g-357 -8.646680993179657e-05 0.9996579244177048\n",
      "g-358 -7.3721403767665e-05 1.000455870473529\n",
      "g-359 0.0004304316404263352 1.0017849051317895\n",
      "g-360 -0.0005962268388331847 1.0022747446667162\n",
      "g-361 4.194479680197013e-05 0.9994007146191233\n",
      "g-362 -7.154826966351469e-05 0.9997957417193334\n",
      "g-363 8.183099929097522e-05 0.9998663365419872\n",
      "g-364 -0.0021339211622788683 1.0089933448426038\n",
      "g-365 2.7032350012401305e-06 0.9998200877444012\n",
      "g-366 -0.00011277229674940055 0.9995790728640291\n",
      "g-367 -6.30731581803649e-05 1.0014813798452682\n",
      "g-368 0.00358636320766716 1.0140529134137517\n",
      "g-371 -0.0003020163302889841 1.0011595559553705\n",
      "g-372 -8.10082531845802e-05 1.000020617312105\n",
      "g-373 -0.0004978995655304952 1.0014510864926092\n",
      "g-374 0.0023831551861756973 1.0096388863704588\n",
      "g-375 -0.0024557983064470803 1.009651892359786\n",
      "g-376 -0.00016085750120705577 1.0002752896020008\n",
      "g-377 0.0008676630554911895 1.0033292347642562\n",
      "g-378 0.00014372319922649018 1.0004423755638552\n",
      "g-379 -0.0006016056488181628 1.0026134404186509\n",
      "g-380 4.303025394266947e-05 0.9992098011678314\n",
      "g-381 -2.584069821793623e-05 0.9993874238856361\n",
      "g-382 1.300920409661336e-05 0.9998842304265093\n",
      "g-383 3.438162860764616e-05 0.9996263197513651\n",
      "g-384 -0.00013844867808949195 0.999806591005266\n",
      "g-385 -0.016306802186374064 1.0623341140415565\n",
      "g-387 -0.00010027484756840901 0.9999579865786397\n",
      "g-388 -0.0004403658807918749 1.0019830437237915\n",
      "g-389 0.00025468074881871593 1.0010034019844134\n",
      "g-390 -0.0006298663875964384 1.0020308936053686\n",
      "g-391 2.486428413058829e-05 0.9992145061081426\n",
      "g-392 0.027233692138379693 1.100298202693916\n",
      "g-393 0.002199363549732731 1.008291928770062\n",
      "g-394 0.0005714355153124714 1.0030322364161774\n",
      "g-395 0.0007323085459530719 1.0024620902503552\n",
      "g-396 -0.00010671461584594512 0.999508331024957\n",
      "g-397 1.5164661283060334e-07 1.000017107995745\n",
      "g-398 4.799423984529166e-06 0.9993814553523346\n",
      "g-399 -0.00014428422718045287 0.9997382272611802\n",
      "g-400 -0.0004540262398579202 1.0020555008623948\n",
      "g-401 -1.4240787344113952e-05 0.9997259392812112\n",
      "g-402 0.0008488231799692274 1.0031424093351688\n",
      "g-403 3.557389686275486e-05 1.0001145942574905\n",
      "g-404 -2.9405159528587288e-05 0.9994101641167118\n",
      "g-405 -0.0003638872737892606 1.0010296928472364\n",
      "g-406 -0.01660686640860657 1.0638508372905684\n",
      "g-408 -9.409669645184e-05 1.000014422751131\n",
      "g-409 0.0005133276151380897 1.0020422083695635\n",
      "g-410 7.869480176540845e-05 0.9998800850587323\n",
      "g-411 -0.020530056957663308 1.0768896423688314\n",
      "g-412 5.507471180582764e-05 0.9994593717679344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g-413 -0.0001468403541331751 1.0001925170946624\n",
      "g-414 -0.0003599127067282363 1.000930217463099\n",
      "g-415 -0.0002686857295471402 1.0002494045867107\n",
      "g-416 -6.791963316977216e-05 0.9999761015104424\n",
      "g-417 0.04398780408857785 1.1545418812926918\n",
      "g-418 3.542462677839846e-05 1.0004048143200053\n",
      "g-419 0.000319205986986933 1.000742944935079\n",
      "g-420 0.00010336036421055288 0.9996854542113559\n",
      "g-421 -0.0007872990623085061 1.0025248490880707\n",
      "g-422 0.00024766310526672927 1.0005347789924632\n",
      "g-423 -0.003350512613591671 1.012815787059476\n",
      "g-424 0.0029019921398072916 1.0112421366200424\n",
      "g-425 -6.310806149709559e-05 0.999864405147701\n",
      "g-426 -1.3444900450342463e-05 0.9997293936459648\n",
      "g-427 0.0008912246550443706 1.00312686712729\n",
      "g-428 1.263852251129537e-05 1.000515290135725\n",
      "g-429 1.359700517569553e-06 1.0001169213933616\n",
      "g-431 -0.00030565390329633933 1.0010724020477333\n",
      "g-432 8.867503877749868e-05 0.9996213396026729\n",
      "g-433 -0.0003008722062034469 1.001082736125666\n",
      "g-434 -0.0006973488195214741 1.0025297806601539\n",
      "g-436 0.0005412387972183424 1.0022733039742893\n",
      "g-437 0.0005907286603137434 1.0019898801761133\n",
      "g-439 -0.002594840749189877 1.0106779856328931\n",
      "g-440 -8.825043848798583e-06 0.9997117841287427\n",
      "g-441 -3.9715689515057425e-05 0.9995354762963454\n",
      "g-442 -2.5811323255381414e-05 0.9992433897013812\n",
      "g-443 0.002530374074339745 1.0095044113138099\n",
      "g-444 -0.00019094454004772127 0.9998360652598973\n",
      "g-445 6.117664785564954e-05 0.9994082201265851\n",
      "g-446 7.565499923645232e-05 0.9994718429423735\n",
      "g-447 -2.8803769597370493e-05 0.9996188988097574\n",
      "g-450 1.9415217612710353e-06 1.0001817666895594\n",
      "g-451 4.0852561583865215e-06 0.99953930741478\n",
      "g-453 7.138559709272564e-05 0.9998593625478177\n",
      "g-454 -2.9734428773853967e-05 0.9998796297641166\n",
      "g-455 0.0002817040349619655 1.0003107273787153\n",
      "g-456 0.0001989299050910492 1.0001721193856699\n",
      "g-457 0.0005783302630084813 1.0022353078879624\n",
      "g-458 -0.00028680369825089853 1.0005930479937855\n",
      "g-459 0.00012429283255129827 1.000719684221549\n",
      "g-460 0.027630196669846868 1.1015099056928217\n",
      "g-461 6.535284663455515e-05 0.9998551616837038\n",
      "g-462 2.790290326574537e-06 0.9997118553338279\n",
      "g-463 5.1632799199051355e-05 0.999450978617518\n",
      "g-464 -0.0010336307672908017 1.0041323493764618\n",
      "g-465 -0.0003191185261244178 1.0007312727189672\n",
      "g-466 -4.887456034078021e-05 1.0002088770191377\n",
      "g-467 0.0019051639943279436 1.0069518443965884\n",
      "g-468 0.002498344476254863 1.0102069093762276\n",
      "g-469 2.504889100182906e-05 0.999978805539926\n",
      "g-470 -0.0007234063569350836 1.0029001766459047\n",
      "g-471 4.964168126376138e-05 0.999491307943952\n",
      "g-472 0.00010193898413013756 0.9997517905516897\n",
      "g-473 -2.786877442490178e-05 0.9994184806517955\n",
      "g-474 -0.0003998502480648469 1.001179099592604\n",
      "g-475 7.349167891374024e-05 0.9995556400679239\n",
      "g-476 -0.00011043157772435002 0.9998676542360789\n",
      "g-478 0.0025221918905548447 1.010346828482672\n",
      "g-479 -0.0004623868197601816 1.0016872612327163\n",
      "g-480 0.00012639210183894783 1.0004761041321513\n",
      "g-482 -9.891974213368013e-05 1.0000484421927671\n",
      "g-483 6.0197653077119144e-05 0.9994832101940986\n",
      "g-484 0.0016769357097242117 1.006590252734028\n",
      "g-485 0.0001131890994283466 0.9997593830718018\n",
      "g-486 -0.0015791598555560048 1.0060941345512284\n",
      "g-487 0.00024427921170536176 1.0011618238342477\n",
      "g-488 -7.930839625627945e-05 1.0002924072086778\n",
      "g-489 -0.014751993396967644 1.0563330139643423\n",
      "g-490 -5.447790631277157e-05 0.9996782530073073\n",
      "g-491 0.00011897045479987976 0.999375631744683\n",
      "g-492 9.304652205488155e-06 0.99982156052764\n",
      "g-493 6.179203612421085e-05 0.9993696124563041\n",
      "g-495 0.0003286836358088165 1.003847232923598\n",
      "g-497 -0.0019277043127259581 1.0072345471444681\n",
      "g-498 -0.00030513706266969276 1.00072391438703\n",
      "g-499 0.000219629783409143 1.0011849077283237\n",
      "g-500 0.0028921377256851547 1.01118741095697\n",
      "g-502 9.302660605217356e-05 0.9993062370926855\n",
      "g-503 -0.003791477862646369 1.0155205738055764\n",
      "g-504 0.0047363583601962 1.0187324891886158\n",
      "g-506 -0.0006595322382316542 1.0025039714820554\n",
      "g-507 9.504246957456226e-05 0.9994195080549797\n",
      "g-508 -0.019444940462419603 1.0734756738587812\n",
      "g-509 -1.7429965475702816e-05 0.9996534696569218\n",
      "g-510 -3.781630505388506e-05 0.9996131363700202\n",
      "g-511 -5.254918627913637e-05 0.9995948431231269\n",
      "g-512 0.007474090424264645 1.0294700011670264\n",
      "g-515 -6.075117804511175e-06 0.9994584523798372\n",
      "g-516 -2.425769122430012e-05 0.9997166151299935\n",
      "g-517 -3.359355867958254e-05 0.9997609620696435\n",
      "g-518 -0.00015550974187018824 0.9996927355022596\n",
      "g-519 3.8213413752338104e-05 0.9999571035382738\n",
      "g-520 -0.00021182454130909138 1.0004654263031891\n",
      "g-521 -0.0005903053390229004 1.0025993630282108\n",
      "g-522 -0.001997062113772155 1.0082288098237344\n",
      "g-523 2.223002940589028e-05 0.9992318986085611\n",
      "g-524 0.00010271366313710555 0.9995332146428711\n",
      "g-525 -6.987779419810898e-06 0.999588843940178\n",
      "g-527 -5.9420358088872116e-05 1.0001824063515343\n",
      "g-528 -4.429825286767605e-05 0.9995187814094372\n",
      "g-529 0.00037811472351807827 1.0004789563291068\n",
      "g-531 2.459112457515227e-05 0.999849537377119\n",
      "g-532 3.587409919009628e-05 0.9994260243691578\n",
      "g-533 -6.275761030392053e-05 1.0000271670053298\n",
      "g-535 0.003510439250514877 1.0143391814701046\n",
      "g-537 1.7657368782619555e-05 0.9998690526649204\n",
      "g-538 5.7461523907068184e-05 0.9994797520828214\n",
      "g-539 5.5557498688532184e-05 0.9994138282516694\n",
      "g-540 -0.0007140075716653983 1.0027557618478935\n",
      "g-541 0.008290303704580447 1.0325888111829926\n",
      "g-542 9.162563172889152e-05 0.9994573987396724\n",
      "g-543 3.093407424366546e-05 1.000398927675016\n",
      "g-544 7.444766486779077e-05 1.000241736166708\n",
      "g-546 0.002562788216043993 1.0099998770162422\n",
      "g-547 3.9227145675358125e-05 0.9993907982495849\n",
      "g-548 -0.00029067674349074094 1.001131650468843\n",
      "g-549 -0.0001463167521723697 0.9996870865474702\n",
      "g-551 0.0009338527016331981 1.0034065602731097\n",
      "g-554 -5.5089443357166215e-06 0.9994249020462289\n",
      "g-556 -0.00011081405052461379 1.0001238107852801\n",
      "g-557 0.00012104254218578292 1.0006338026827553\n",
      "g-558 -0.00013350748232151486 1.000417803549404\n",
      "g-559 -0.0002969777057510361 1.0009582864046516\n",
      "g-562 -1.5746584816693964e-05 0.999212118693913\n",
      "g-563 0.00028261851353302036 1.0017450730839557\n",
      "g-564 -0.0003273512061919225 1.00171121766795\n",
      "g-565 -0.0003720023752590128 1.000647664415917\n",
      "g-566 2.0848446967425505e-05 0.9997082970506239\n",
      "g-567 6.142322736894694e-05 0.9992815757897197\n",
      "g-568 -0.010551863502776121 1.0406662513517364\n",
      "g-569 -0.0035982842204573704 1.0139980817846292\n",
      "g-570 5.591690140850064e-05 0.9998486692431237\n",
      "g-571 -0.000319345469452806 1.0012959659519585\n",
      "g-572 0.00010122012569067003 0.9994747539499822\n",
      "g-574 -0.00026138367790378434 1.0001722485405642\n",
      "g-575 5.313660475727031e-05 0.9995079454268339\n",
      "g-577 0.0009177423136130406 1.0031875527673368\n",
      "g-578 0.0012356446582671122 1.004315390537524\n",
      "g-579 -0.00044380902038593554 1.0015349641568028\n",
      "g-580 9.81638308324308e-05 1.0006479121420875\n",
      "g-581 2.0113993841629838e-05 0.9994705466014363\n",
      "g-582 8.431056768401919e-05 1.000107803688515\n",
      "g-583 9.397829699977361e-06 1.0001034867305936\n",
      "g-584 -0.00016703610055773783 0.999876746928769\n",
      "g-585 3.20512739163156e-05 1.000007027621339\n",
      "g-586 -0.00017179854295741684 1.0000591179947405\n",
      "g-587 7.558090928082524e-05 1.0003484414968564\n",
      "g-588 -0.003134765975129879 1.0128211324095577\n",
      "g-589 0.00010735353581110994 0.9999908761954422\n",
      "g-590 -0.00016403595255544529 1.0000476871042183\n",
      "g-591 -4.35290859722794e-05 0.9997994738840406\n",
      "g-592 4.324675199306021e-05 0.9994499803833417\n",
      "g-593 6.36781541577672e-05 0.9994080789349882\n",
      "g-594 6.21733878507514e-05 0.9997213064537115\n",
      "g-596 0.0021240966237747166 1.0085253186313512\n",
      "g-597 -0.0003903715709157206 1.0012961550998358\n",
      "g-598 -1.0712507351092104e-05 1.0000761193129963\n",
      "g-599 0.00011671342698570641 0.9993732928736543\n",
      "g-603 0.0005213411394015745 1.001354113021254\n",
      "g-604 -0.00018876538562111815 1.000861725506544\n",
      "g-605 -4.3647753450114064e-05 0.9999983317030441\n",
      "g-606 1.3958239936616644e-05 0.9996041668592326\n",
      "g-608 9.345883545589737e-05 0.9998506266645817\n",
      "g-609 7.659690586370274e-05 0.9999595915178684\n",
      "g-610 -6.704819315000117e-05 0.9996127023670046\n",
      "g-612 -0.00013572758571480612 1.0005662664890524\n",
      "g-613 -0.00010454638830196813 0.9997072071910319\n",
      "g-614 -0.0003043837787547288 1.0006876233558635\n",
      "g-615 -7.938915532993555e-05 0.9997341455372699\n",
      "g-616 9.226524163999379e-05 0.9994147803151638\n",
      "g-617 -0.00029393723485811476 1.0009744589037015\n",
      "g-618 -0.0005127944081333084 0.9997068649544336\n",
      "g-619 0.0020436007500921815 1.0084804590354972\n",
      "g-620 0.00016535334246327917 0.9998386705685922\n",
      "g-621 -4.6186625599774365e-05 0.9995684775707981\n",
      "g-622 -0.00012447893037171182 0.9997925928671831\n",
      "g-623 0.0002640350306655632 1.0005186119694733\n",
      "g-624 -0.0017261765688886958 1.007206924448293\n",
      "g-625 0.0006741489261658866 1.0033131563144724\n",
      "g-626 2.166602025820823e-05 0.9993977138349182\n",
      "g-627 3.3105328630873066e-05 0.999247846785159\n",
      "g-628 0.0007803621358847711 1.0031013250584568\n",
      "g-629 0.0073746721932813454 1.0290781233322286\n",
      "g-630 -0.0003880034109508269 1.0008804882461266\n",
      "g-631 0.00011016584379294616 1.0001348951299807\n",
      "g-632 -0.002089506331883196 1.008750044656345\n",
      "g-633 -4.8003287993646835e-05 0.9997645924314195\n",
      "g-634 2.2071238949758095e-05 0.9994874253515478\n",
      "g-635 0.0006729028651702327 1.0024436763824855\n",
      "g-636 0.000977048427152382 1.0033161608396712\n",
      "g-638 -0.0006752330313510197 1.0022809525753262\n",
      "g-639 9.251692104305104e-05 0.9994866309479224\n",
      "g-640 0.00016015934740908126 1.0005667535645635\n",
      "g-641 -0.00012384964514847968 1.0000844466950978\n",
      "g-642 5.207526971540263e-05 0.9995517558996737\n",
      "g-643 -0.0015344928806587715 1.0061690214571635\n",
      "g-644 -0.015804575400222298 1.0613080650698228\n",
      "g-645 1.5575995605302705e-05 0.9997561829172104\n",
      "g-646 0.0047715789795347505 1.0187411309769894\n",
      "g-647 0.00019276891284375906 1.000524893090209\n",
      "g-648 0.0010847480496518791 1.0042447762919666\n",
      "g-649 -6.76237129487362e-05 0.9994355020046399\n",
      "g-651 0.0005174773565495283 1.0011837632550482\n",
      "g-652 -0.0007637653940007955 1.0026592314116323\n",
      "g-653 -0.0006698942294054954 1.0020460181112252\n",
      "g-655 0.00013342940977704735 0.999841670453981\n",
      "g-656 -1.852957100571395e-05 0.9998418755804901\n",
      "g-657 -0.00012913725439687106 1.000414721551762\n",
      "g-658 0.0006661606204813722 1.002280050365722\n",
      "g-659 1.5674992361843506e-05 0.9997122009565291\n",
      "g-660 0.00010254432669751679 0.9997759047681152\n",
      "g-661 -0.00020014861931807649 1.0006883367784094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g-662 7.015157967856963e-05 0.9994965392198006\n",
      "g-663 0.0001688687480979832 0.9999207470122549\n",
      "g-664 -0.00042005846076367554 1.0009943926043527\n",
      "g-665 -0.0013798136765696932 1.0045421923782922\n",
      "g-666 0.00010301547038907287 0.9998401190485882\n",
      "g-667 -0.0002018860406917672 1.0000207916310362\n",
      "g-668 3.4726471806727e-06 0.9996986042198724\n",
      "g-669 -0.002129757378663416 1.0091844187531396\n",
      "g-670 -0.00038038543436517806 1.0020252994861254\n",
      "g-671 -0.00018948651900980288 1.0009080581091896\n",
      "g-672 -0.009114142675257675 1.0355312533728362\n",
      "g-673 -0.0003664295884627404 1.00084076747467\n",
      "g-674 -0.004972941916024866 1.0195340499741892\n",
      "g-675 6.8033420117136005e-06 0.999995698717916\n",
      "g-676 0.0002420231334699168 1.0009428103694702\n",
      "g-677 -0.000375217299066061 1.0012010115231371\n",
      "g-678 -0.0007993598676973173 1.003684177859586\n",
      "g-679 0.00010371155925009526 1.0001529978394759\n",
      "g-680 6.258098411238148e-05 0.9998282006976745\n",
      "g-681 -0.0002264154825830829 1.0007726968396988\n",
      "g-682 0.00013113400828856762 0.9997174505029446\n",
      "g-683 -0.00030029870935650664 1.0009146265594446\n",
      "g-684 -0.00025609313468864976 1.0005334453992585\n",
      "g-685 -0.002210416574344131 1.0088529833406692\n",
      "g-686 0.0003345925637334223 1.00055663233836\n",
      "g-688 0.00036007079372078505 1.001920614944292\n",
      "g-689 0.0006662041961777782 1.001732235736836\n",
      "g-690 2.6295806168944638e-05 0.9995771289558818\n",
      "g-691 -0.010645216897032414 1.0412847563766718\n",
      "g-692 -1.4209205910125814e-05 0.9993404161548657\n",
      "g-693 0.00045634247105142686 1.001418160274508\n",
      "g-694 -5.3149215454251075e-05 0.9996343943374257\n",
      "g-696 2.939323815785864e-07 0.9993742421303603\n",
      "g-697 0.002078168242046641 1.0086428080174683\n",
      "g-698 -0.00010255452645243649 0.9997576335686673\n",
      "g-699 0.000275933377738717 1.000813412018343\n",
      "g-701 0.0001916740532122643 1.0004447398929948\n",
      "g-702 -0.00010217881409659998 0.9998898221737054\n",
      "g-704 -0.0016631229203128452 1.006404883232669\n",
      "g-705 -0.005931331794694088 1.0234758435901783\n",
      "g-706 8.407874422449386e-05 0.9997050551704515\n",
      "g-707 0.0038351016875123427 0.989193332495882\n",
      "g-708 0.0009653598745621311 1.0041315413312393\n",
      "g-710 0.0008020664694013946 1.0026680398409933\n",
      "g-711 0.0010532946226255177 1.0054139592124343\n",
      "g-713 -0.00015038806981319846 0.9997556412561199\n",
      "g-714 1.9131233885588726e-05 0.999458326832348\n",
      "g-715 -0.000121954619500967 1.000018864491462\n",
      "g-717 0.00032790292818483664 1.0005621104738305\n",
      "g-720 9.155872358690989e-05 0.9999822904496783\n",
      "g-721 0.0024064881941470847 1.0098813246182186\n",
      "g-722 0.00042520438970195044 1.001017336729368\n",
      "g-723 0.007141968627318623 1.0282468986214497\n",
      "g-724 0.0009370668547895865 1.0035427844462217\n",
      "g-725 -7.528412392642562e-05 1.0000156623711591\n",
      "g-726 -0.00035359847457327743 1.0014860229380877\n",
      "g-727 -5.1270196389725915e-05 0.999821989532379\n",
      "g-728 0.00011482695341225876 0.9994228863115465\n",
      "g-729 0.00022268537357137278 1.000716071114148\n",
      "g-730 -2.6170988987591998e-06 0.9995525357816576\n",
      "g-731 0.011013577843920297 1.0441436497402237\n",
      "g-732 4.0754321079578354e-05 0.9995359328972774\n",
      "g-734 -5.600764102769486e-05 0.99961378051442\n",
      "g-735 6.834067846271736e-05 1.0001012761802943\n",
      "g-736 -0.0011250244667897688 1.0046998950350294\n",
      "g-737 -0.0004076437519534919 1.0013160927487816\n",
      "g-739 -0.0003996217802971508 1.0011978224459361\n",
      "g-740 9.003208655479572e-06 0.9994041170550753\n",
      "g-741 0.0001205758174836524 1.000460060860332\n",
      "g-742 -7.914125844717906e-05 1.0000211127959713\n",
      "g-743 -0.00023843662921763746 1.0003443102240477\n",
      "g-744 0.034473179723233806 1.1242653880680158\n",
      "g-745 0.002301575680744719 1.0088062224082575\n",
      "g-746 1.1240085954966099e-05 0.9998962036924991\n",
      "g-747 0.00014284757965433 1.0004067003444816\n",
      "g-748 0.000603015639426562 1.001847938528747\n",
      "g-749 0.00011560321192738093 1.0002607243303634\n",
      "g-750 0.0009061009171935049 1.0037107583044136\n",
      "g-751 0.00016225168730782033 1.0006788103324038\n",
      "g-752 8.265865825905793e-05 0.999879884674311\n",
      "g-753 0.000868828791489181 1.0028985327922193\n",
      "g-754 3.443531686048475e-05 0.9996657854728251\n",
      "g-757 -0.0003744041578685135 1.0014411866841926\n",
      "g-758 0.0008008136060439968 1.003022322113818\n",
      "g-759 -0.0017342714786516263 1.0100254287336459\n",
      "g-760 -0.030083242336263697 1.1102758271686284\n",
      "g-761 -0.0029189593712400583 1.012567111114479\n",
      "g-762 1.1901879835291833e-05 0.9996663267579856\n",
      "g-763 -0.00018203546474650326 1.0000737131900606\n",
      "g-764 0.0009896897494919659 1.0031958161958365\n",
      "g-765 3.419271394997779e-05 0.9995672581293835\n",
      "g-766 2.378141952432783e-05 1.000580771310933\n",
      "g-767 5.77287441739006e-05 0.9998858490456577\n",
      "g-768 0.00025306904737297644 1.0007445145577905\n",
      "g-769 -0.0015845753257253024 1.0068504089944887\n",
      "g-770 -0.0007396645828869475 1.002108446865941\n",
      "g-771 0.0016842447335608897 1.0080677781373275\n",
      "c-0 -0.026012429819970682 1.0964306844668228\n",
      "c-1 -0.019043155519004283 1.0721885686985428\n",
      "c-2 -0.03157677242782929 1.115101314598892\n",
      "c-4 -0.03349047444949758 1.1211868096888382\n",
      "c-5 -0.022166110192194704 1.0828115871192245\n",
      "c-6 -0.0375622070104899 1.1344627879376945\n",
      "c-7 -0.0009469587734326564 1.0039855481530378\n",
      "c-8 -0.02693934151919207 1.0994278359419556\n",
      "c-9 -0.0006645803106134242 1.0023999591964683\n",
      "c-10 -0.03355286739135655 1.1219271854373314\n",
      "c-11 -0.031841003698077214 1.1159799328501399\n",
      "c-12 -0.030025075711200055 1.1096759447771312\n",
      "c-13 -0.035219504184714485 1.127078484219191\n",
      "c-14 -0.002781208702380528 1.010739395721891\n",
      "c-15 -0.025524835013243128 1.0944347062967246\n",
      "c-17 -0.0332942460058295 1.1209823238798\n",
      "c-18 -0.03417224750759046 1.1234472489819707\n",
      "c-19 -0.0043106016287436395 1.0170868453917994\n",
      "c-20 -0.027893996252148563 1.1024225409993516\n",
      "c-21 -0.025476301412586486 1.0946573721060764\n",
      "c-22 -0.0039597248917312925 1.0159215102797616\n",
      "c-23 -0.0016326481541072098 1.0069174993155676\n",
      "c-25 -0.003833681853129623 1.0157069334191922\n",
      "c-26 -0.007621929389728505 1.0299230109306368\n",
      "c-27 -0.004908301906748997 1.0198283753125856\n",
      "c-28 -0.0022072731692686946 1.008484791169346\n",
      "c-29 -0.00030135352169269043 1.0006956532252165\n",
      "c-30 -0.0002976381640594334 1.0007231085186212\n",
      "c-31 -0.0071748109747761385 1.0282234093154918\n",
      "c-33 -0.012391363929638303 1.0480699031903962\n",
      "c-34 -0.004209902217294962 1.016739792832574\n",
      "c-36 -0.0041846744941137146 1.0165651618834661\n",
      "c-38 -0.013798291220843651 1.0535852981636462\n",
      "c-39 -0.003918190038401932 1.0160169505334846\n",
      "c-40 -0.004058889547713381 1.0163706981604914\n",
      "c-41 -0.00589812304310055 1.0243701876942446\n",
      "c-42 -0.005864167348713945 1.023742339683451\n",
      "c-43 -0.004227229753106392 1.017250429343886\n",
      "c-44 -0.004424802876308636 1.017468626151088\n",
      "c-46 -0.001677257597766084 1.0068002705815842\n",
      "c-47 -0.0010763576597357368 1.0037645249360292\n",
      "c-48 -0.0024095283112616273 1.0093133086431936\n",
      "c-50 -0.001765160859255534 1.0070228477312146\n",
      "c-51 -0.026177161977879723 1.0967228762771306\n",
      "c-52 -0.023805801323573603 1.0887045191325997\n",
      "c-53 -0.01628196282322183 1.0624449118414026\n",
      "c-54 -0.011602884811694452 1.0447334662129997\n",
      "c-55 -0.04911061910448687 1.1708397012852683\n",
      "c-56 -0.0017084232219417774 1.006349892371913\n",
      "c-57 -0.012480699656738732 1.048610293518574\n",
      "c-59 -0.05378538269124793 1.1851854795361274\n",
      "c-60 -0.055714284510838326 1.1906343094929392\n",
      "c-62 -0.022102149003610436 1.0829267701492662\n",
      "c-63 -0.054224572109202354 1.186499441140978\n",
      "c-64 -0.014323627538404543 1.055247135580937\n",
      "c-65 -0.04381511008464077 1.1542233733525677\n",
      "c-66 -0.023960454922786183 1.0898765368331766\n",
      "c-67 -0.02589561904145741 1.0958416260543944\n",
      "c-70 -0.05944013593716723 1.2017984966617221\n",
      "c-71 -0.0106252088794668 1.0422208227046756\n",
      "c-72 -0.0433984081146017 1.1529060230825112\n",
      "c-73 -0.03960190891262202 1.141184099379804\n",
      "c-75 -0.03825996449052449 1.1367179431548997\n",
      "c-76 -3.955127688350214e-05 0.9996707437109585\n",
      "c-77 -0.021974428909633477 1.0824539005487803\n",
      "c-79 -0.00897057815328123 1.0352296288130527\n",
      "c-80 -0.046884908315247914 1.1638679981526288\n",
      "c-81 -0.041845113869292266 1.1481541617486228\n",
      "c-83 -0.04699948220713892 1.1644087528713103\n",
      "c-84 -0.04529944096447949 1.1591727960570761\n",
      "c-85 -0.02868597369890429 1.1051920897461431\n",
      "c-86 -0.003269114453650273 1.0130899140101566\n",
      "c-87 -0.009498118049573689 1.0370016621735445\n",
      "c-89 -0.027922356367463146 1.103161457946218\n",
      "c-91 -0.047447625755128765 1.1664228906247511\n",
      "c-92 -0.013176300469613614 1.0513716542996172\n",
      "c-93 -0.0594100631543763 1.2018796644855743\n",
      "c-94 -0.0635164985072589 1.2144928799464976\n",
      "c-95 -0.0051186171592672945 1.020642369173464\n",
      "c-96 -0.04791493486536471 1.1675848808680134\n",
      "c-97 -0.005099993351100715 1.0206973429636723\n",
      "c-98 -0.00804158908389384 1.0317101172578524\n",
      "c-99 -0.0007964373287775516 1.0025837044294421\n",
      "kridge_acat_inhibitor 0.0009679132037396543 0.0015015342229869474\n",
      "kridge_acetylcholine_receptor_agonist 0.008540583180062468 0.005383869626801562\n",
      "kridge_acetylcholine_receptor_antagonist 0.013567723379940996 0.0073957423725010294\n",
      "kridge_acetylcholinesterase_inhibitor 0.003239162125586287 0.0027249210622164086\n",
      "kridge_adenosine_receptor_agonist 0.002364049503644969 0.0024841073530671542\n",
      "kridge_adenosine_receptor_antagonist 0.00436131673960246 0.003152678668504583\n",
      "kridge_adrenergic_receptor_agonist 0.012157259885888583 0.006849779153381017\n",
      "kridge_adrenergic_receptor_antagonist 0.016118744915194425 0.007742852691699518\n",
      "kridge_akt_inhibitor 0.0025402215502825305 0.004102606789990749\n",
      "kridge_alk_inhibitor 0.0016470440063497311 0.002596835284020889\n",
      "kridge_androgen_receptor_agonist 0.002087804644672766 0.0022411503549835936\n",
      "kridge_androgen_receptor_antagonist 0.004001731159342345 0.003137669728236868\n",
      "kridge_anesthetic_-_local 0.003582614506051637 0.0029212275948919068\n",
      "kridge_angiogenesis_inhibitor 0.001613614597610993 0.001764509082284198\n",
      "kridge_angiotensin_receptor_antagonist 0.0017039172502974057 0.0021052685752201796\n",
      "kridge_anti-inflammatory 0.0031474415441816077 0.0034687785318766534\n",
      "kridge_antibiotic 0.0015379409447800934 0.0018809233654511158\n",
      "kridge_antioxidant 0.0032364771553456584 0.002964999804162365\n",
      "kridge_antiprotozoal 0.0016288513539389044 0.002129422853792618\n",
      "kridge_antiviral 0.0009885727857597336 0.0016030174960662354\n",
      "kridge_apoptosis_stimulant 0.0018016765188960638 0.0020543057586071547\n",
      "kridge_aromatase_inhibitor 0.0020417884518113077 0.0022653509423003005\n",
      "kridge_atpase_inhibitor 0.00323530236927094 0.0021341873374037413\n",
      "kridge_aurora_kinase_inhibitor 0.003706342567151754 0.006133546955780766\n",
      "kridge_bacterial_30s_ribosomal_subunit_inhibitor 0.002584569297749782 0.0028684072629635037\n",
      "kridge_bacterial_50s_ribosomal_subunit_inhibitor 0.003416854401191358 0.0032325094778326165\n",
      "kridge_bacterial_antifolate 0.001558680202736882 0.0021527856249974843\n",
      "kridge_bacterial_cell_wall_synthesis_inhibitor 0.008684392045428892 0.0051986625327157905\n",
      "kridge_bacterial_dna_gyrase_inhibitor 0.00398850324031064 0.003400186274315486\n",
      "kridge_bacterial_dna_inhibitor 0.005248963908452536 0.0038974566698429824\n",
      "kridge_bcl_inhibitor 0.0009960210388842495 0.001626997383727522\n",
      "kridge_bcr-abl_inhibitor 0.0013093140785511287 0.001710667636665603\n",
      "kridge_benzodiazepine_receptor_agonist 0.0030078484273587352 0.002854607599516925\n",
      "kridge_beta_amyloid_inhibitor 0.0010360467241411788 0.0015116524534499712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kridge_bromodomain_inhibitor 0.0020884272631574432 0.0026761989116421553\n",
      "kridge_btk_inhibitor 0.0011912776390855784 0.00223079394290803\n",
      "kridge_calcium_channel_blocker 0.012533839286073056 0.006325035174075205\n",
      "kridge_cannabinoid_receptor_agonist 0.0018466728137510268 0.0022399646934310948\n",
      "kridge_cannabinoid_receptor_antagonist 0.002438573469965061 0.0026470380656918617\n",
      "kridge_carbonic_anhydrase_inhibitor 0.0015758098628883242 0.00189843446750408\n",
      "kridge_casein_kinase_inhibitor 0.0015524950975176646 0.0020039714809702257\n",
      "kridge_cc_chemokine_receptor_antagonist 0.004401901303348937 0.003404236892371685\n",
      "kridge_cdk_inhibitor 0.00839555724725416 0.02557990007962004\n",
      "kridge_chelating_agent 0.002359389588508494 0.0026121261716377797\n",
      "kridge_chk_inhibitor 0.0006836890806613023 0.0016297091214179176\n",
      "kridge_chloride_channel_blocker 0.0019300775900910868 0.00220065838761178\n",
      "kridge_cholesterol_inhibitor 0.0021073894133025284 0.002260595075961982\n",
      "kridge_cholinergic_receptor_antagonist 0.002297637938536491 0.0024230260514878387\n",
      "kridge_corticosteroid_agonist 0.001397986369102134 0.0038920560710391746\n",
      "kridge_cyclooxygenase_inhibitor 0.01945137054910956 0.009840054197559633\n",
      "kridge_cytochrome_p450_inhibitor 0.004449324235056305 0.003584049667448747\n",
      "kridge_dihydrofolate_reductase_inhibitor 0.0012413271090597065 0.0016010737147082532\n",
      "kridge_dipeptidyl_peptidase_inhibitor 0.0010810783892453665 0.0018068447010415874\n",
      "kridge_dna_alkylating_agent 0.0019470846262414695 0.002413528218628801\n",
      "kridge_dna_inhibitor 0.016154233489834694 0.009687676389179408\n",
      "kridge_dopamine_receptor_agonist 0.005511487892196346 0.0036100175360640682\n",
      "kridge_dopamine_receptor_antagonist 0.019074220993063985 0.00950190473201484\n",
      "kridge_egfr_inhibitor 0.013078218414911493 0.021261188721716343\n",
      "kridge_estrogen_receptor_agonist 0.0070680656014442626 0.004641356670047896\n",
      "kridge_estrogen_receptor_antagonist 0.0020723658988268637 0.002420190392925839\n",
      "kridge_faah_inhibitor 0.0015286545699880368 0.0023023888307614243\n",
      "kridge_fatty_acid_receptor_agonist 0.0011120785945991204 0.001875589690912434\n",
      "kridge_fgfr_inhibitor 0.0019778469904908995 0.0026753340463847677\n",
      "kridge_flt3_inhibitor 0.010173406203159666 0.01167534158038805\n",
      "kridge_fungal_squalene_epoxidase_inhibitor 0.0010711262950586203 0.0018307847326806692\n",
      "kridge_gaba_receptor_agonist 0.004585325725910164 0.0034696740454494917\n",
      "kridge_gaba_receptor_antagonist 0.0072855641636316625 0.004537059183642012\n",
      "kridge_gamma_secretase_inhibitor 0.0023774492043754296 0.0038219230289061015\n",
      "kridge_glucocorticoid_receptor_agonist 0.010598938720169876 0.024804696380069848\n",
      "kridge_glutamate_receptor_agonist 0.0033111985585264785 0.002756019979282823\n",
      "kridge_glutamate_receptor_antagonist 0.016475000861256764 0.007944963207561979\n",
      "kridge_gsk_inhibitor 0.0020482302700472878 0.00321164428878102\n",
      "kridge_hcv_inhibitor 0.003141292941585481 0.002749189800795852\n",
      "kridge_hdac_inhibitor 0.002269844135536301 0.0027738879914294256\n",
      "kridge_histamine_receptor_agonist 0.0025962207433534892 0.0026787834200411326\n",
      "kridge_histamine_receptor_antagonist 0.01090986789387421 0.005757828123822318\n",
      "kridge_histone_lysine_demethylase_inhibitor 0.0009530556082658684 0.002088341130229991\n",
      "kridge_histone_lysine_methyltransferase_inhibitor 0.0014385191871392475 0.0023751217555259357\n",
      "kridge_hiv_inhibitor 0.003215968211994737 0.0032185548268562265\n",
      "kridge_hmgcr_inhibitor 0.011244941380676828 0.016907232120236926\n",
      "kridge_hsp_inhibitor 0.0014035265930553873 0.0029961772653448434\n",
      "kridge_igf-1_inhibitor 0.0015898634749424393 0.0024539861046299133\n",
      "kridge_ikk_inhibitor 0.0009474136123643491 0.0020967778221047035\n",
      "kridge_imidazoline_receptor_agonist 0.0012979920328729266 0.0017341220210970957\n",
      "kridge_immunosuppressant 0.0028930118226201547 0.004558343813877981\n",
      "kridge_insulin_secretagogue 0.0012807851669190738 0.0018394918245603828\n",
      "kridge_insulin_sensitizer 0.0020726383346087564 0.0029920801717151623\n",
      "kridge_integrin_inhibitor 0.001781237360815002 0.002011874119961351\n",
      "kridge_jak_inhibitor 0.0031212517703152246 0.004525452178694793\n",
      "kridge_kit_inhibitor 0.010307255991661901 0.011702835580385757\n",
      "kridge_leukotriene_receptor_antagonist 0.002722520498662371 0.002753582201603988\n",
      "kridge_lipoxygenase_inhibitor 0.002495935363499913 0.002615261950478872\n",
      "kridge_mdm_inhibitor 0.0011106941931158035 0.0025410710008581744\n",
      "kridge_mek_inhibitor 0.0019468020364068414 0.004495704001491777\n",
      "kridge_membrane_integrity_inhibitor 0.00318221736104009 0.002832411209222798\n",
      "kridge_mineralocorticoid_receptor_antagonist 0.0010786779346760858 0.0016423176916392109\n",
      "kridge_monoamine_oxidase_inhibitor 0.003857523195654956 0.0031805505861727855\n",
      "kridge_mtor_inhibitor 0.003499411532597953 0.008652792272060781\n",
      "kridge_mucolytic_agent 0.002109907139433636 0.0023590899886147456\n",
      "kridge_neuropeptide_receptor_antagonist 0.001538305020514117 0.0022628598566543506\n",
      "kridge_nfkb_inhibitor 0.008074365644692336 0.017144720161900554\n",
      "kridge_nitric_oxide_donor 0.0011458119990774016 0.001782665165693352\n",
      "kridge_nitric_oxide_synthase_inhibitor 0.0010817622508018283 0.0016901941959579924\n",
      "kridge_opioid_receptor_agonist 0.0026668378679498396 0.0026901052328494584\n",
      "kridge_opioid_receptor_antagonist 0.003977053387495445 0.003529342886044707\n",
      "kridge_orexin_receptor_antagonist 0.0016582913406513054 0.0019418635929309422\n",
      "kridge_p38_mapk_inhibitor 0.0024590891582119525 0.004090415900944829\n",
      "kridge_p-glycoprotein_inhibitor 0.0010434171375599698 0.0016118514874372764\n",
      "kridge_parp_inhibitor 0.0026481964498243954 0.0035216620596950168\n",
      "kridge_pdgfr_inhibitor 0.01117058929708667 0.011935871388031443\n",
      "kridge_phosphodiesterase_inhibitor 0.01173859773170839 0.0064562323611403235\n",
      "kridge_phospholipase_inhibitor 0.0010821888241449855 0.0016275125529300364\n",
      "kridge_pi3k_inhibitor 0.005140372221558688 0.006026570443458969\n",
      "kridge_pkc_inhibitor 0.001262311958217216 0.001788028553268839\n",
      "kridge_potassium_channel_activator 0.0023409310002964175 0.0025427339539890446\n",
      "kridge_potassium_channel_antagonist 0.00441057925777725 0.0032826790411532945\n",
      "kridge_ppar_receptor_agonist 0.004473062960579132 0.004954824861086921\n",
      "kridge_ppar_receptor_antagonist 0.0013484967518930262 0.0017293689076487715\n",
      "kridge_progesterone_receptor_agonist 0.005373240681970319 0.004511837169018931\n",
      "kridge_prostaglandin_inhibitor 0.0016089487616295036 0.001997463723584315\n",
      "kridge_prostanoid_receptor_antagonist 0.0037390084892911595 0.003056764434799052\n",
      "kridge_proteasome_inhibitor 0.0037468214296390396 0.019524829964047585\n",
      "kridge_protein_kinase_inhibitor 0.0019208420151808612 0.0021870874094146587\n",
      "kridge_protein_synthesis_inhibitor 0.0031632129683042136 0.0016688537424742853\n",
      "kridge_radiopaque_medium 0.002474017850586554 0.002405294994992441\n",
      "kridge_raf_inhibitor 0.005860793457781275 0.01985773200561825\n",
      "kridge_retinoid_receptor_agonist 0.0027455608190394033 0.004305330833084922\n",
      "kridge_rho_associated_kinase_inhibitor 0.0013911185134801705 0.0023808021690726\n",
      "kridge_ribonucleoside_reductase_inhibitor 0.0011767194585221897 0.001717308282530809\n",
      "kridge_rna_polymerase_inhibitor 0.000875146205366125 0.0014064724968496077\n",
      "kridge_serotonin_receptor_agonist 0.010558903035282764 0.005642301419561747\n",
      "kridge_serotonin_receptor_antagonist 0.01797646087141621 0.009757143747173016\n",
      "kridge_serotonin_reuptake_inhibitor 0.0018949889910443525 0.002300320644086614\n",
      "kridge_sigma_receptor_agonist 0.0015917777337558167 0.0018365657505465202\n",
      "kridge_sigma_receptor_antagonist 0.001553263353997244 0.0021656678623405107\n",
      "kridge_smoothened_receptor_antagonist 0.0009601543565825023 0.001537436365169477\n",
      "kridge_sodium_channel_inhibitor 0.011743873320076462 0.006469108943586249\n",
      "kridge_sphingosine_receptor_agonist 0.0011157060631223146 0.0016582711855291704\n",
      "kridge_src_inhibitor 0.0025138056466515123 0.00312933124377052\n",
      "kridge_tachykinin_antagonist 0.002706094961469858 0.002666931752171585\n",
      "kridge_tgf-beta_receptor_inhibitor 0.0009840930686432798 0.0030222779856226172\n",
      "kridge_thymidylate_synthase_inhibitor 0.0014251988946935733 0.0020975473070655054\n",
      "kridge_tlr_agonist 0.0013616395012237448 0.0017215798972667028\n",
      "kridge_tnf_inhibitor 0.001497348904069569 0.002012020942910625\n",
      "kridge_topoisomerase_inhibitor 0.002409611885255165 0.003316283000061553\n",
      "kridge_trpv_agonist 0.0009715069342646681 0.0018651223331342605\n",
      "kridge_trpv_antagonist 0.0020760760612974624 0.0024557434696060565\n",
      "kridge_tubulin_inhibitor 0.01087990212306831 0.028103410965640525\n",
      "kridge_tyrosine_kinase_inhibitor 0.0030453662857099326 0.0030939483366414504\n",
      "kridge_vegfr_inhibitor 0.007230060288047321 0.007157575319779848\n",
      "kridge_vitamin_b 0.0010746405288542605 0.0016682995141242862\n",
      "kridge_vitamin_d_receptor_agonist 0.0015108640846040083 0.0029076890312433605\n",
      "kridge_wnt_inhibitor 0.0012927827590492596 0.0017552977311425628\n",
      "kmeans_g_0 24.499705580367984 14.575528140338626\n",
      "kmeans_g_1 24.27857214739505 14.38895066864198\n",
      "kmeans_g_2 73.88168361010761 5.389843508292667\n",
      "kmeans_g_3 66.36414050269366 4.633260420256777\n",
      "kmeans_g_4 64.15049063538832 4.565402688389629\n",
      "kmeans_g_5 43.14270500863043 6.00641122962899\n",
      "kmeans_g_6 29.488787156837788 10.718923803996342\n",
      "kmeans_c_0 6.724326219046678 7.43380725980398\n",
      "kmeans_c_1 5.956169520062871 8.33444240368168\n",
      "kmeans_c_2 30.788935100514575 5.180802436044504\n",
      "kmeans_c_3 44.37567107522664 8.188354569600815\n",
      "kmeans_c_4 6.467324242776625 8.816612344226364\n",
      "kmeans_c_5 11.813542348377693 4.868516617621923\n",
      "kmeans_c_6 20.48426992934527 3.182072478519573\n",
      "cp_time_24 0.3264989976307636 0.4689321935811938\n",
      "cp_time_48 0.3463641334062329 0.47581090834067913\n",
      "cp_time_72 0.3271368689630035 0.4691677076782738\n",
      "cp_dose_D1 0.5101148168398032 0.49989768001091706\n",
      "cp_dose_D2 0.4898851831601968 0.49989768001091706\n"
     ]
    }
   ],
   "source": [
    "# Standarize\n",
    "for colname in feature_cols_ini:\n",
    "    valor_fold = folds[colname].values\n",
    "    valor_tst = test_noctl[colname].values\n",
    "    mean_v = np.mean(valor_fold)\n",
    "    std_v = np.std(valor_fold)\n",
    "    if std_v==0:\n",
    "        std_v=1e-5\n",
    "    folds[colname] = (valor_fold-mean_v)/std_v\n",
    "    test_noctl[colname] = (valor_tst-mean_v)/std_v\n",
    "    print(colname, mean_v, std_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:45.282986Z",
     "start_time": "2020-12-01T17:39:45.278785Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def mean_auc(y_true, y_pred):\n",
    "    auc_mean = []\n",
    "    for ncol in range(y_true.shape[1]):\n",
    "        if np.sum(y_true[:,ncol])>0:\n",
    "            auc_mean.append(roc_auc_score(y_true[:,ncol], y_pred[:, ncol]))\n",
    "    return np.mean(auc_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:45.307035Z",
     "start_time": "2020-12-01T17:39:45.284515Z"
    }
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:45.338993Z",
     "start_time": "2020-12-01T17:39:45.309120Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:45.360276Z",
     "start_time": "2020-12-01T17:39:45.341329Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if not scheduler.__class__ ==  torch.optim.lr_scheduler.ReduceLROnPlateau:\n",
    "            scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        y_true.append(targets.cpu().detach().numpy())\n",
    "        y_pred.append(outputs.sigmoid().cpu().detach().numpy())\n",
    "    \n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    control_loss = log_loss_multi(y_true, y_pred)\n",
    "    final_loss /= len(dataloader)\n",
    "    return final_loss, control_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        y_true.append(targets.cpu().detach().numpy())\n",
    "        y_pred.append(outputs.sigmoid().cpu().detach().numpy())\n",
    "        \n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    control_loss = log_loss_multi(y_true, y_pred)\n",
    "    final_loss /= len(dataloader)\n",
    "    return final_loss, control_loss, y_true, y_pred\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        y_pred.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:45.388435Z",
     "start_time": "2020-12-01T17:39:45.361918Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(drop1_feat) #0.20\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(drop2_feat) #0.20\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(drop3_feat) #0.25\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "#         x = F.relu(self.dense1(x))\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "#         x = F.relu(self.dense2(x))\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Run K-folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:45.415310Z",
     "start_time": "2020-12-01T17:39:45.390532Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed_fold, seed_run, display=2):\n",
    "    seed_everything(seed_run)\n",
    "    train = folds.copy()\n",
    "    test_ = test_noctl.copy()\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=3)\n",
    "    \n",
    "#     loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss_val = nn.BCEWithLogitsLoss()\n",
    "    loss_tr = nn.BCEWithLogitsLoss() #SmoothBCEwLogits(smoothing =1E-3)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), num_targets))\n",
    "    best_loss = np.inf\n",
    "    best_auc_loss = 0.0\n",
    "    best_epoch = 0\n",
    "    res = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss, mloss_train = train_fn(model, optimizer, scheduler, loss_tr, trainloader, DEVICE)\n",
    "#         print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, mloss_valid, y_true, valid_preds = valid_fn(model, loss_val, validloader, DEVICE)\n",
    "        auc_loss = mean_auc(y_true, valid_preds)\n",
    "    \n",
    "        if mloss_valid < best_loss:\n",
    "            best_loss = mloss_valid\n",
    "            best_auc_loss = auc_loss\n",
    "            best_epoch = epoch\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), output_dir / f'ann_model_seedfold{seed_fold}_seedrun{seed_run}_fold__{fold}.pth')\n",
    "        elif(EARLY_STOP == True):\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "        if scheduler.__class__ !=  torch.optim.lr_scheduler.ReduceLROnPlateau:\n",
    "            lr = scheduler.get_last_lr()\n",
    "        else:\n",
    "            lr = [0.0]\n",
    "        \n",
    "        # Save results\n",
    "        # ------------\n",
    "        res.append(dict({'epoch':epoch, 'lr':lr[0], 'trn_loss':mloss_train, 'val_loss':mloss_valid, 'auc_loss':auc_loss, 'best_epoch':best_epoch, 'best_loss':best_loss, 'best_auc_loss':best_auc_loss}))\n",
    "        \n",
    "        res_df = pd.DataFrame(res)\n",
    "        res_df.to_csv(output_dir / f'res_seedfold{seed_fold}_seedrun{seed_run}_fold{fold}_.csv')\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1 )\n",
    "        min_val = res_df[['trn_loss','val_loss']].min().min()\n",
    "        ax.plot(res_df['trn_loss'])\n",
    "        ax.plot(res_df['val_loss'])\n",
    "        plt.ylim((min_val,0.020))\n",
    "        plt.title(f\"logloss in fold={fold} min={res_df['val_loss'].min()}\")\n",
    "        fig.savefig(output_dir / f'loss_seedfold{seed_fold}_seedrun{seed_run}_fold{fold}_.png')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1 )\n",
    "        ax.plot(res_df['lr'])\n",
    "        plt.title(f\"lr in fold={fold}\")\n",
    "        fig.savefig(output_dir / f'lr_seedfold{seed_fold}_seedrun{seed_run}_fold{fold}_.png')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1 )\n",
    "        ax.plot(res_df['auc_loss'])\n",
    "        plt.title(f\"auc_loss in fold={fold} best={res_df['best_auc_loss']}\")\n",
    "        fig.savefig(output_dir / f'auc_loss_seedfold{seed_fold}_seedrun{seed_run}_fold{fold}_.png')\n",
    "        plt.close(fig)\n",
    "        if display==2:\n",
    "            print(f\"seed_fold:{seed_fold} seedrun{seed_run} FOLD:{fold} EPOCH:{epoch:2d} lr:{lr[0]:.9f} trn_loss:{mloss_train:.6f} val_loss:{mloss_valid:.6f} auc_loss={auc_loss:.3f} best_epoch:{best_epoch} best_loss:{best_loss:.6f} best_auc_loss={best_auc_loss:.3f}\")\n",
    "    \n",
    "    if display>=1:\n",
    "        print(f\"BEST!! seed_fold:{seed_fold} seedrun{seed_run} FOLD:{fold} EPOCH:{epoch:2d} lr:{lr[0]:.9f} trn_loss:{mloss_train:.6f} val_loss:{mloss_valid:.6f} auc_loss={auc_loss:.3f} best_epoch:{best_epoch} best_loss:{best_loss:.6f} best_auc_loss={best_auc_loss:.3f}\")\n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(output_dir / f'ann_model_seedfold{seed_fold}_seedrun{seed_run}_fold__{fold}.pth'))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions_tst = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions_tst = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions_tst, best_loss, best_auc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:45.441375Z",
     "start_time": "2020-12-01T17:39:45.416763Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed_fold, seed_run, display=2):\n",
    "    global losses_list\n",
    "    oof_kfold = np.zeros((len(folds), len(target_cols)))\n",
    "    predictions_kfold = np.zeros((len(test_noctl), len(target_cols)))\n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_, val_loss_, best_auc_loss_ = run_training(fold, seed_fold, seed_run, display)\n",
    "        predictions_kfold += pred_ / NFOLDS\n",
    "        oof_kfold += oof_\n",
    "        losses_list.append({'seed_fold':seed_fold, 'seed_run':seed_run, 'fold':fold, 'val_loss':val_loss_, 'auc_loss':best_auc_loss_})\n",
    "    return oof_kfold, predictions_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T17:39:45.478782Z",
     "start_time": "2020-12-01T17:39:45.443583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pca_G-0',\n",
       " 'pca_G-1',\n",
       " 'pca_G-2',\n",
       " 'pca_G-3',\n",
       " 'pca_G-4',\n",
       " 'pca_G-5',\n",
       " 'pca_G-6',\n",
       " 'pca_G-7',\n",
       " 'pca_G-8',\n",
       " 'pca_G-9',\n",
       " 'pca_G-10',\n",
       " 'pca_G-11',\n",
       " 'pca_G-12',\n",
       " 'pca_G-13',\n",
       " 'pca_G-14',\n",
       " 'pca_G-15',\n",
       " 'pca_G-16',\n",
       " 'pca_G-17',\n",
       " 'pca_G-18',\n",
       " 'pca_G-19',\n",
       " 'pca_G-20',\n",
       " 'pca_G-21',\n",
       " 'pca_G-22',\n",
       " 'pca_G-23',\n",
       " 'pca_G-24',\n",
       " 'pca_G-25',\n",
       " 'pca_G-26',\n",
       " 'pca_G-27',\n",
       " 'pca_G-28',\n",
       " 'pca_C-0',\n",
       " 'pca_C-1',\n",
       " 'pca_C-2',\n",
       " 'pca_C-3',\n",
       " 'g-0',\n",
       " 'g-1',\n",
       " 'g-2',\n",
       " 'g-3',\n",
       " 'g-4',\n",
       " 'g-6',\n",
       " 'g-8',\n",
       " 'g-11',\n",
       " 'g-12',\n",
       " 'g-13',\n",
       " 'g-14',\n",
       " 'g-16',\n",
       " 'g-17',\n",
       " 'g-19',\n",
       " 'g-20',\n",
       " 'g-21',\n",
       " 'g-22',\n",
       " 'g-24',\n",
       " 'g-26',\n",
       " 'g-27',\n",
       " 'g-28',\n",
       " 'g-29',\n",
       " 'g-30',\n",
       " 'g-32',\n",
       " 'g-33',\n",
       " 'g-34',\n",
       " 'g-35',\n",
       " 'g-36',\n",
       " 'g-37',\n",
       " 'g-38',\n",
       " 'g-39',\n",
       " 'g-40',\n",
       " 'g-41',\n",
       " 'g-43',\n",
       " 'g-44',\n",
       " 'g-45',\n",
       " 'g-46',\n",
       " 'g-47',\n",
       " 'g-48',\n",
       " 'g-49',\n",
       " 'g-50',\n",
       " 'g-51',\n",
       " 'g-52',\n",
       " 'g-53',\n",
       " 'g-55',\n",
       " 'g-56',\n",
       " 'g-57',\n",
       " 'g-58',\n",
       " 'g-59',\n",
       " 'g-60',\n",
       " 'g-61',\n",
       " 'g-62',\n",
       " 'g-63',\n",
       " 'g-64',\n",
       " 'g-65',\n",
       " 'g-66',\n",
       " 'g-67',\n",
       " 'g-68',\n",
       " 'g-69',\n",
       " 'g-70',\n",
       " 'g-71',\n",
       " 'g-72',\n",
       " 'g-73',\n",
       " 'g-75',\n",
       " 'g-76',\n",
       " 'g-77',\n",
       " 'g-78',\n",
       " 'g-79',\n",
       " 'g-80',\n",
       " 'g-81',\n",
       " 'g-83',\n",
       " 'g-84',\n",
       " 'g-85',\n",
       " 'g-86',\n",
       " 'g-87',\n",
       " 'g-88',\n",
       " 'g-89',\n",
       " 'g-90',\n",
       " 'g-91',\n",
       " 'g-92',\n",
       " 'g-93',\n",
       " 'g-94',\n",
       " 'g-95',\n",
       " 'g-96',\n",
       " 'g-97',\n",
       " 'g-98',\n",
       " 'g-99',\n",
       " 'g-100',\n",
       " 'g-101',\n",
       " 'g-102',\n",
       " 'g-103',\n",
       " 'g-105',\n",
       " 'g-106',\n",
       " 'g-107',\n",
       " 'g-108',\n",
       " 'g-109',\n",
       " 'g-110',\n",
       " 'g-111',\n",
       " 'g-112',\n",
       " 'g-113',\n",
       " 'g-114',\n",
       " 'g-115',\n",
       " 'g-117',\n",
       " 'g-118',\n",
       " 'g-119',\n",
       " 'g-120',\n",
       " 'g-121',\n",
       " 'g-122',\n",
       " 'g-123',\n",
       " 'g-124',\n",
       " 'g-125',\n",
       " 'g-126',\n",
       " 'g-127',\n",
       " 'g-128',\n",
       " 'g-129',\n",
       " 'g-130',\n",
       " 'g-133',\n",
       " 'g-134',\n",
       " 'g-135',\n",
       " 'g-136',\n",
       " 'g-137',\n",
       " 'g-138',\n",
       " 'g-139',\n",
       " 'g-140',\n",
       " 'g-141',\n",
       " 'g-142',\n",
       " 'g-143',\n",
       " 'g-144',\n",
       " 'g-146',\n",
       " 'g-147',\n",
       " 'g-148',\n",
       " 'g-149',\n",
       " 'g-150',\n",
       " 'g-151',\n",
       " 'g-152',\n",
       " 'g-154',\n",
       " 'g-155',\n",
       " 'g-156',\n",
       " 'g-157',\n",
       " 'g-158',\n",
       " 'g-159',\n",
       " 'g-160',\n",
       " 'g-161',\n",
       " 'g-162',\n",
       " 'g-163',\n",
       " 'g-164',\n",
       " 'g-165',\n",
       " 'g-166',\n",
       " 'g-167',\n",
       " 'g-168',\n",
       " 'g-169',\n",
       " 'g-170',\n",
       " 'g-171',\n",
       " 'g-172',\n",
       " 'g-173',\n",
       " 'g-174',\n",
       " 'g-175',\n",
       " 'g-176',\n",
       " 'g-177',\n",
       " 'g-178',\n",
       " 'g-179',\n",
       " 'g-180',\n",
       " 'g-181',\n",
       " 'g-182',\n",
       " 'g-183',\n",
       " 'g-185',\n",
       " 'g-186',\n",
       " 'g-187',\n",
       " 'g-188',\n",
       " 'g-189',\n",
       " 'g-190',\n",
       " 'g-191',\n",
       " 'g-192',\n",
       " 'g-194',\n",
       " 'g-195',\n",
       " 'g-196',\n",
       " 'g-197',\n",
       " 'g-199',\n",
       " 'g-200',\n",
       " 'g-201',\n",
       " 'g-202',\n",
       " 'g-203',\n",
       " 'g-205',\n",
       " 'g-206',\n",
       " 'g-207',\n",
       " 'g-208',\n",
       " 'g-209',\n",
       " 'g-210',\n",
       " 'g-211',\n",
       " 'g-212',\n",
       " 'g-213',\n",
       " 'g-214',\n",
       " 'g-215',\n",
       " 'g-217',\n",
       " 'g-218',\n",
       " 'g-220',\n",
       " 'g-221',\n",
       " 'g-222',\n",
       " 'g-223',\n",
       " 'g-224',\n",
       " 'g-225',\n",
       " 'g-226',\n",
       " 'g-227',\n",
       " 'g-228',\n",
       " 'g-229',\n",
       " 'g-230',\n",
       " 'g-231',\n",
       " 'g-232',\n",
       " 'g-233',\n",
       " 'g-234',\n",
       " 'g-235',\n",
       " 'g-236',\n",
       " 'g-237',\n",
       " 'g-239',\n",
       " 'g-240',\n",
       " 'g-241',\n",
       " 'g-242',\n",
       " 'g-243',\n",
       " 'g-244',\n",
       " 'g-245',\n",
       " 'g-246',\n",
       " 'g-247',\n",
       " 'g-248',\n",
       " 'g-249',\n",
       " 'g-250',\n",
       " 'g-251',\n",
       " 'g-252',\n",
       " 'g-253',\n",
       " 'g-254',\n",
       " 'g-255',\n",
       " 'g-256',\n",
       " 'g-257',\n",
       " 'g-258',\n",
       " 'g-259',\n",
       " 'g-260',\n",
       " 'g-261',\n",
       " 'g-262',\n",
       " 'g-263',\n",
       " 'g-264',\n",
       " 'g-265',\n",
       " 'g-266',\n",
       " 'g-268',\n",
       " 'g-269',\n",
       " 'g-270',\n",
       " 'g-271',\n",
       " 'g-272',\n",
       " 'g-273',\n",
       " 'g-274',\n",
       " 'g-275',\n",
       " 'g-276',\n",
       " 'g-277',\n",
       " 'g-278',\n",
       " 'g-279',\n",
       " 'g-280',\n",
       " 'g-281',\n",
       " 'g-282',\n",
       " 'g-283',\n",
       " 'g-284',\n",
       " 'g-285',\n",
       " 'g-286',\n",
       " 'g-287',\n",
       " 'g-288',\n",
       " 'g-289',\n",
       " 'g-291',\n",
       " 'g-292',\n",
       " 'g-293',\n",
       " 'g-295',\n",
       " 'g-297',\n",
       " 'g-298',\n",
       " 'g-299',\n",
       " 'g-300',\n",
       " 'g-301',\n",
       " 'g-302',\n",
       " 'g-303',\n",
       " 'g-304',\n",
       " 'g-305',\n",
       " 'g-306',\n",
       " 'g-308',\n",
       " 'g-309',\n",
       " 'g-311',\n",
       " 'g-312',\n",
       " 'g-313',\n",
       " 'g-314',\n",
       " 'g-315',\n",
       " 'g-316',\n",
       " 'g-317',\n",
       " 'g-318',\n",
       " 'g-319',\n",
       " 'g-320',\n",
       " 'g-321',\n",
       " 'g-322',\n",
       " 'g-323',\n",
       " 'g-324',\n",
       " 'g-325',\n",
       " 'g-326',\n",
       " 'g-327',\n",
       " 'g-328',\n",
       " 'g-329',\n",
       " 'g-330',\n",
       " 'g-332',\n",
       " 'g-333',\n",
       " 'g-334',\n",
       " 'g-335',\n",
       " 'g-336',\n",
       " 'g-337',\n",
       " 'g-338',\n",
       " 'g-339',\n",
       " 'g-340',\n",
       " 'g-341',\n",
       " 'g-342',\n",
       " 'g-343',\n",
       " 'g-344',\n",
       " 'g-345',\n",
       " 'g-346',\n",
       " 'g-347',\n",
       " 'g-348',\n",
       " 'g-349',\n",
       " 'g-350',\n",
       " 'g-351',\n",
       " 'g-352',\n",
       " 'g-353',\n",
       " 'g-354',\n",
       " 'g-355',\n",
       " 'g-356',\n",
       " 'g-357',\n",
       " 'g-358',\n",
       " 'g-359',\n",
       " 'g-360',\n",
       " 'g-361',\n",
       " 'g-362',\n",
       " 'g-363',\n",
       " 'g-364',\n",
       " 'g-365',\n",
       " 'g-366',\n",
       " 'g-367',\n",
       " 'g-368',\n",
       " 'g-371',\n",
       " 'g-372',\n",
       " 'g-373',\n",
       " 'g-374',\n",
       " 'g-375',\n",
       " 'g-376',\n",
       " 'g-377',\n",
       " 'g-378',\n",
       " 'g-379',\n",
       " 'g-380',\n",
       " 'g-381',\n",
       " 'g-382',\n",
       " 'g-383',\n",
       " 'g-384',\n",
       " 'g-385',\n",
       " 'g-387',\n",
       " 'g-388',\n",
       " 'g-389',\n",
       " 'g-390',\n",
       " 'g-391',\n",
       " 'g-392',\n",
       " 'g-393',\n",
       " 'g-394',\n",
       " 'g-395',\n",
       " 'g-396',\n",
       " 'g-397',\n",
       " 'g-398',\n",
       " 'g-399',\n",
       " 'g-400',\n",
       " 'g-401',\n",
       " 'g-402',\n",
       " 'g-403',\n",
       " 'g-404',\n",
       " 'g-405',\n",
       " 'g-406',\n",
       " 'g-408',\n",
       " 'g-409',\n",
       " 'g-410',\n",
       " 'g-411',\n",
       " 'g-412',\n",
       " 'g-413',\n",
       " 'g-414',\n",
       " 'g-415',\n",
       " 'g-416',\n",
       " 'g-417',\n",
       " 'g-418',\n",
       " 'g-419',\n",
       " 'g-420',\n",
       " 'g-421',\n",
       " 'g-422',\n",
       " 'g-423',\n",
       " 'g-424',\n",
       " 'g-425',\n",
       " 'g-426',\n",
       " 'g-427',\n",
       " 'g-428',\n",
       " 'g-429',\n",
       " 'g-431',\n",
       " 'g-432',\n",
       " 'g-433',\n",
       " 'g-434',\n",
       " 'g-436',\n",
       " 'g-437',\n",
       " 'g-439',\n",
       " 'g-440',\n",
       " 'g-441',\n",
       " 'g-442',\n",
       " 'g-443',\n",
       " 'g-444',\n",
       " 'g-445',\n",
       " 'g-446',\n",
       " 'g-447',\n",
       " 'g-450',\n",
       " 'g-451',\n",
       " 'g-453',\n",
       " 'g-454',\n",
       " 'g-455',\n",
       " 'g-456',\n",
       " 'g-457',\n",
       " 'g-458',\n",
       " 'g-459',\n",
       " 'g-460',\n",
       " 'g-461',\n",
       " 'g-462',\n",
       " 'g-463',\n",
       " 'g-464',\n",
       " 'g-465',\n",
       " 'g-466',\n",
       " 'g-467',\n",
       " 'g-468',\n",
       " 'g-469',\n",
       " 'g-470',\n",
       " 'g-471',\n",
       " 'g-472',\n",
       " 'g-473',\n",
       " 'g-474',\n",
       " 'g-475',\n",
       " 'g-476',\n",
       " 'g-478',\n",
       " 'g-479',\n",
       " 'g-480',\n",
       " 'g-482',\n",
       " 'g-483',\n",
       " 'g-484',\n",
       " 'g-485',\n",
       " 'g-486',\n",
       " 'g-487',\n",
       " 'g-488',\n",
       " 'g-489',\n",
       " 'g-490',\n",
       " 'g-491',\n",
       " 'g-492',\n",
       " 'g-493',\n",
       " 'g-495',\n",
       " 'g-497',\n",
       " 'g-498',\n",
       " 'g-499',\n",
       " 'g-500',\n",
       " 'g-502',\n",
       " 'g-503',\n",
       " 'g-504',\n",
       " 'g-506',\n",
       " 'g-507',\n",
       " 'g-508',\n",
       " 'g-509',\n",
       " 'g-510',\n",
       " 'g-511',\n",
       " 'g-512',\n",
       " 'g-515',\n",
       " 'g-516',\n",
       " 'g-517',\n",
       " 'g-518',\n",
       " 'g-519',\n",
       " 'g-520',\n",
       " 'g-521',\n",
       " 'g-522',\n",
       " 'g-523',\n",
       " 'g-524',\n",
       " 'g-525',\n",
       " 'g-527',\n",
       " 'g-528',\n",
       " 'g-529',\n",
       " 'g-531',\n",
       " 'g-532',\n",
       " 'g-533',\n",
       " 'g-535',\n",
       " 'g-537',\n",
       " 'g-538',\n",
       " 'g-539',\n",
       " 'g-540',\n",
       " 'g-541',\n",
       " 'g-542',\n",
       " 'g-543',\n",
       " 'g-544',\n",
       " 'g-546',\n",
       " 'g-547',\n",
       " 'g-548',\n",
       " 'g-549',\n",
       " 'g-551',\n",
       " 'g-554',\n",
       " 'g-556',\n",
       " 'g-557',\n",
       " 'g-558',\n",
       " 'g-559',\n",
       " 'g-562',\n",
       " 'g-563',\n",
       " 'g-564',\n",
       " 'g-565',\n",
       " 'g-566',\n",
       " 'g-567',\n",
       " 'g-568',\n",
       " 'g-569',\n",
       " 'g-570',\n",
       " 'g-571',\n",
       " 'g-572',\n",
       " 'g-574',\n",
       " 'g-575',\n",
       " 'g-577',\n",
       " 'g-578',\n",
       " 'g-579',\n",
       " 'g-580',\n",
       " 'g-581',\n",
       " 'g-582',\n",
       " 'g-583',\n",
       " 'g-584',\n",
       " 'g-585',\n",
       " 'g-586',\n",
       " 'g-587',\n",
       " 'g-588',\n",
       " 'g-589',\n",
       " 'g-590',\n",
       " 'g-591',\n",
       " 'g-592',\n",
       " 'g-593',\n",
       " 'g-594',\n",
       " 'g-596',\n",
       " 'g-597',\n",
       " 'g-598',\n",
       " 'g-599',\n",
       " 'g-603',\n",
       " 'g-604',\n",
       " 'g-605',\n",
       " 'g-606',\n",
       " 'g-608',\n",
       " 'g-609',\n",
       " 'g-610',\n",
       " 'g-612',\n",
       " 'g-613',\n",
       " 'g-614',\n",
       " 'g-615',\n",
       " 'g-616',\n",
       " 'g-617',\n",
       " 'g-618',\n",
       " 'g-619',\n",
       " 'g-620',\n",
       " 'g-621',\n",
       " 'g-622',\n",
       " 'g-623',\n",
       " 'g-624',\n",
       " 'g-625',\n",
       " 'g-626',\n",
       " 'g-627',\n",
       " 'g-628',\n",
       " 'g-629',\n",
       " 'g-630',\n",
       " 'g-631',\n",
       " 'g-632',\n",
       " 'g-633',\n",
       " 'g-634',\n",
       " 'g-635',\n",
       " 'g-636',\n",
       " 'g-638',\n",
       " 'g-639',\n",
       " 'g-640',\n",
       " 'g-641',\n",
       " 'g-642',\n",
       " 'g-643',\n",
       " 'g-644',\n",
       " 'g-645',\n",
       " 'g-646',\n",
       " 'g-647',\n",
       " 'g-648',\n",
       " 'g-649',\n",
       " 'g-651',\n",
       " 'g-652',\n",
       " 'g-653',\n",
       " 'g-655',\n",
       " 'g-656',\n",
       " 'g-657',\n",
       " 'g-658',\n",
       " 'g-659',\n",
       " 'g-660',\n",
       " 'g-661',\n",
       " 'g-662',\n",
       " 'g-663',\n",
       " 'g-664',\n",
       " 'g-665',\n",
       " 'g-666',\n",
       " 'g-667',\n",
       " 'g-668',\n",
       " 'g-669',\n",
       " 'g-670',\n",
       " 'g-671',\n",
       " 'g-672',\n",
       " 'g-673',\n",
       " 'g-674',\n",
       " 'g-675',\n",
       " 'g-676',\n",
       " 'g-677',\n",
       " 'g-678',\n",
       " 'g-679',\n",
       " 'g-680',\n",
       " 'g-681',\n",
       " 'g-682',\n",
       " 'g-683',\n",
       " 'g-684',\n",
       " 'g-685',\n",
       " 'g-686',\n",
       " 'g-688',\n",
       " 'g-689',\n",
       " 'g-690',\n",
       " 'g-691',\n",
       " 'g-692',\n",
       " 'g-693',\n",
       " 'g-694',\n",
       " 'g-696',\n",
       " 'g-697',\n",
       " 'g-698',\n",
       " 'g-699',\n",
       " 'g-701',\n",
       " 'g-702',\n",
       " 'g-704',\n",
       " 'g-705',\n",
       " 'g-706',\n",
       " 'g-707',\n",
       " 'g-708',\n",
       " 'g-710',\n",
       " 'g-711',\n",
       " 'g-713',\n",
       " 'g-714',\n",
       " 'g-715',\n",
       " 'g-717',\n",
       " 'g-720',\n",
       " 'g-721',\n",
       " 'g-722',\n",
       " 'g-723',\n",
       " 'g-724',\n",
       " 'g-725',\n",
       " 'g-726',\n",
       " 'g-727',\n",
       " 'g-728',\n",
       " 'g-729',\n",
       " 'g-730',\n",
       " 'g-731',\n",
       " 'g-732',\n",
       " 'g-734',\n",
       " 'g-735',\n",
       " 'g-736',\n",
       " 'g-737',\n",
       " 'g-739',\n",
       " 'g-740',\n",
       " 'g-741',\n",
       " 'g-742',\n",
       " 'g-743',\n",
       " 'g-744',\n",
       " 'g-745',\n",
       " 'g-746',\n",
       " 'g-747',\n",
       " 'g-748',\n",
       " 'g-749',\n",
       " 'g-750',\n",
       " 'g-751',\n",
       " 'g-752',\n",
       " 'g-753',\n",
       " 'g-754',\n",
       " 'g-757',\n",
       " 'g-758',\n",
       " 'g-759',\n",
       " 'g-760',\n",
       " 'g-761',\n",
       " 'g-762',\n",
       " 'g-763',\n",
       " 'g-764',\n",
       " 'g-765',\n",
       " 'g-766',\n",
       " 'g-767',\n",
       " 'g-768',\n",
       " 'g-769',\n",
       " 'g-770',\n",
       " 'g-771',\n",
       " 'c-0',\n",
       " 'c-1',\n",
       " 'c-2',\n",
       " 'c-4',\n",
       " 'c-5',\n",
       " 'c-6',\n",
       " 'c-7',\n",
       " 'c-8',\n",
       " 'c-9',\n",
       " 'c-10',\n",
       " 'c-11',\n",
       " 'c-12',\n",
       " 'c-13',\n",
       " 'c-14',\n",
       " 'c-15',\n",
       " 'c-17',\n",
       " 'c-18',\n",
       " 'c-19',\n",
       " 'c-20',\n",
       " 'c-21',\n",
       " 'c-22',\n",
       " 'c-23',\n",
       " 'c-25',\n",
       " 'c-26',\n",
       " 'c-27',\n",
       " 'c-28',\n",
       " 'c-29',\n",
       " 'c-30',\n",
       " 'c-31',\n",
       " 'c-33',\n",
       " 'c-34',\n",
       " 'c-36',\n",
       " 'c-38',\n",
       " 'c-39',\n",
       " 'c-40',\n",
       " 'c-41',\n",
       " 'c-42',\n",
       " 'c-43',\n",
       " 'c-44',\n",
       " 'c-46',\n",
       " 'c-47',\n",
       " 'c-48',\n",
       " 'c-50',\n",
       " 'c-51',\n",
       " 'c-52',\n",
       " 'c-53',\n",
       " 'c-54',\n",
       " 'c-55',\n",
       " 'c-56',\n",
       " 'c-57',\n",
       " 'c-59',\n",
       " 'c-60',\n",
       " 'c-62',\n",
       " 'c-63',\n",
       " 'c-64',\n",
       " 'c-65',\n",
       " 'c-66',\n",
       " 'c-67',\n",
       " 'c-70',\n",
       " 'c-71',\n",
       " 'c-72',\n",
       " 'c-73',\n",
       " 'c-75',\n",
       " 'c-76',\n",
       " 'c-77',\n",
       " 'c-79',\n",
       " 'c-80',\n",
       " 'c-81',\n",
       " 'c-83',\n",
       " 'c-84',\n",
       " 'c-85',\n",
       " 'c-86',\n",
       " 'c-87',\n",
       " 'c-89',\n",
       " 'c-91',\n",
       " 'c-92',\n",
       " 'c-93',\n",
       " 'c-94',\n",
       " 'c-95',\n",
       " 'c-96',\n",
       " 'c-97',\n",
       " 'c-98',\n",
       " 'c-99',\n",
       " 'kridge_acat_inhibitor',\n",
       " 'kridge_acetylcholine_receptor_agonist',\n",
       " 'kridge_acetylcholine_receptor_antagonist',\n",
       " 'kridge_acetylcholinesterase_inhibitor',\n",
       " 'kridge_adenosine_receptor_agonist',\n",
       " 'kridge_adenosine_receptor_antagonist',\n",
       " 'kridge_adrenergic_receptor_agonist',\n",
       " 'kridge_adrenergic_receptor_antagonist',\n",
       " 'kridge_akt_inhibitor',\n",
       " 'kridge_alk_inhibitor',\n",
       " 'kridge_androgen_receptor_agonist',\n",
       " 'kridge_androgen_receptor_antagonist',\n",
       " 'kridge_anesthetic_-_local',\n",
       " 'kridge_angiogenesis_inhibitor',\n",
       " 'kridge_angiotensin_receptor_antagonist',\n",
       " 'kridge_anti-inflammatory',\n",
       " 'kridge_antibiotic',\n",
       " 'kridge_antioxidant',\n",
       " 'kridge_antiprotozoal',\n",
       " 'kridge_antiviral',\n",
       " 'kridge_apoptosis_stimulant',\n",
       " 'kridge_aromatase_inhibitor',\n",
       " 'kridge_atpase_inhibitor',\n",
       " 'kridge_aurora_kinase_inhibitor',\n",
       " 'kridge_bacterial_30s_ribosomal_subunit_inhibitor',\n",
       " 'kridge_bacterial_50s_ribosomal_subunit_inhibitor',\n",
       " 'kridge_bacterial_antifolate',\n",
       " 'kridge_bacterial_cell_wall_synthesis_inhibitor',\n",
       " 'kridge_bacterial_dna_gyrase_inhibitor',\n",
       " 'kridge_bacterial_dna_inhibitor',\n",
       " 'kridge_bcl_inhibitor',\n",
       " 'kridge_bcr-abl_inhibitor',\n",
       " 'kridge_benzodiazepine_receptor_agonist',\n",
       " 'kridge_beta_amyloid_inhibitor',\n",
       " 'kridge_bromodomain_inhibitor',\n",
       " 'kridge_btk_inhibitor',\n",
       " 'kridge_calcium_channel_blocker',\n",
       " 'kridge_cannabinoid_receptor_agonist',\n",
       " 'kridge_cannabinoid_receptor_antagonist',\n",
       " 'kridge_carbonic_anhydrase_inhibitor',\n",
       " 'kridge_casein_kinase_inhibitor',\n",
       " 'kridge_cc_chemokine_receptor_antagonist',\n",
       " 'kridge_cdk_inhibitor',\n",
       " 'kridge_chelating_agent',\n",
       " 'kridge_chk_inhibitor',\n",
       " 'kridge_chloride_channel_blocker',\n",
       " 'kridge_cholesterol_inhibitor',\n",
       " 'kridge_cholinergic_receptor_antagonist',\n",
       " 'kridge_corticosteroid_agonist',\n",
       " 'kridge_cyclooxygenase_inhibitor',\n",
       " 'kridge_cytochrome_p450_inhibitor',\n",
       " 'kridge_dihydrofolate_reductase_inhibitor',\n",
       " 'kridge_dipeptidyl_peptidase_inhibitor',\n",
       " 'kridge_dna_alkylating_agent',\n",
       " 'kridge_dna_inhibitor',\n",
       " 'kridge_dopamine_receptor_agonist',\n",
       " 'kridge_dopamine_receptor_antagonist',\n",
       " 'kridge_egfr_inhibitor',\n",
       " 'kridge_estrogen_receptor_agonist',\n",
       " 'kridge_estrogen_receptor_antagonist',\n",
       " 'kridge_faah_inhibitor',\n",
       " 'kridge_fatty_acid_receptor_agonist',\n",
       " 'kridge_fgfr_inhibitor',\n",
       " 'kridge_flt3_inhibitor',\n",
       " 'kridge_fungal_squalene_epoxidase_inhibitor',\n",
       " 'kridge_gaba_receptor_agonist',\n",
       " 'kridge_gaba_receptor_antagonist',\n",
       " 'kridge_gamma_secretase_inhibitor',\n",
       " 'kridge_glucocorticoid_receptor_agonist',\n",
       " 'kridge_glutamate_receptor_agonist',\n",
       " 'kridge_glutamate_receptor_antagonist',\n",
       " 'kridge_gsk_inhibitor',\n",
       " 'kridge_hcv_inhibitor',\n",
       " 'kridge_hdac_inhibitor',\n",
       " 'kridge_histamine_receptor_agonist',\n",
       " 'kridge_histamine_receptor_antagonist',\n",
       " 'kridge_histone_lysine_demethylase_inhibitor',\n",
       " 'kridge_histone_lysine_methyltransferase_inhibitor',\n",
       " 'kridge_hiv_inhibitor',\n",
       " 'kridge_hmgcr_inhibitor',\n",
       " 'kridge_hsp_inhibitor',\n",
       " 'kridge_igf-1_inhibitor',\n",
       " 'kridge_ikk_inhibitor',\n",
       " 'kridge_imidazoline_receptor_agonist',\n",
       " 'kridge_immunosuppressant',\n",
       " 'kridge_insulin_secretagogue',\n",
       " 'kridge_insulin_sensitizer',\n",
       " 'kridge_integrin_inhibitor',\n",
       " 'kridge_jak_inhibitor',\n",
       " 'kridge_kit_inhibitor',\n",
       " 'kridge_leukotriene_receptor_antagonist',\n",
       " 'kridge_lipoxygenase_inhibitor',\n",
       " 'kridge_mdm_inhibitor',\n",
       " 'kridge_mek_inhibitor',\n",
       " 'kridge_membrane_integrity_inhibitor',\n",
       " 'kridge_mineralocorticoid_receptor_antagonist',\n",
       " 'kridge_monoamine_oxidase_inhibitor',\n",
       " 'kridge_mtor_inhibitor',\n",
       " 'kridge_mucolytic_agent',\n",
       " 'kridge_neuropeptide_receptor_antagonist',\n",
       " 'kridge_nfkb_inhibitor',\n",
       " 'kridge_nitric_oxide_donor',\n",
       " 'kridge_nitric_oxide_synthase_inhibitor',\n",
       " 'kridge_opioid_receptor_agonist',\n",
       " 'kridge_opioid_receptor_antagonist',\n",
       " 'kridge_orexin_receptor_antagonist',\n",
       " 'kridge_p38_mapk_inhibitor',\n",
       " 'kridge_p-glycoprotein_inhibitor',\n",
       " 'kridge_parp_inhibitor',\n",
       " 'kridge_pdgfr_inhibitor',\n",
       " 'kridge_phosphodiesterase_inhibitor',\n",
       " 'kridge_phospholipase_inhibitor',\n",
       " 'kridge_pi3k_inhibitor',\n",
       " 'kridge_pkc_inhibitor',\n",
       " 'kridge_potassium_channel_activator',\n",
       " 'kridge_potassium_channel_antagonist',\n",
       " 'kridge_ppar_receptor_agonist',\n",
       " 'kridge_ppar_receptor_antagonist',\n",
       " 'kridge_progesterone_receptor_agonist',\n",
       " 'kridge_prostaglandin_inhibitor',\n",
       " 'kridge_prostanoid_receptor_antagonist',\n",
       " 'kridge_proteasome_inhibitor',\n",
       " 'kridge_protein_kinase_inhibitor',\n",
       " 'kridge_protein_synthesis_inhibitor',\n",
       " 'kridge_radiopaque_medium',\n",
       " 'kridge_raf_inhibitor',\n",
       " 'kridge_retinoid_receptor_agonist',\n",
       " 'kridge_rho_associated_kinase_inhibitor',\n",
       " 'kridge_ribonucleoside_reductase_inhibitor',\n",
       " 'kridge_rna_polymerase_inhibitor',\n",
       " 'kridge_serotonin_receptor_agonist',\n",
       " 'kridge_serotonin_receptor_antagonist',\n",
       " 'kridge_serotonin_reuptake_inhibitor',\n",
       " 'kridge_sigma_receptor_agonist',\n",
       " 'kridge_sigma_receptor_antagonist',\n",
       " 'kridge_smoothened_receptor_antagonist',\n",
       " 'kridge_sodium_channel_inhibitor',\n",
       " 'kridge_sphingosine_receptor_agonist',\n",
       " 'kridge_src_inhibitor',\n",
       " 'kridge_tachykinin_antagonist',\n",
       " 'kridge_tgf-beta_receptor_inhibitor',\n",
       " 'kridge_thymidylate_synthase_inhibitor',\n",
       " 'kridge_tlr_agonist',\n",
       " 'kridge_tnf_inhibitor',\n",
       " 'kridge_topoisomerase_inhibitor',\n",
       " 'kridge_trpv_agonist',\n",
       " 'kridge_trpv_antagonist',\n",
       " 'kridge_tubulin_inhibitor',\n",
       " 'kridge_tyrosine_kinase_inhibitor',\n",
       " 'kridge_vegfr_inhibitor',\n",
       " 'kridge_vitamin_b',\n",
       " 'kridge_vitamin_d_receptor_agonist',\n",
       " 'kridge_wnt_inhibitor',\n",
       " 'kmeans_g_0',\n",
       " 'kmeans_g_1',\n",
       " 'kmeans_g_2',\n",
       " 'kmeans_g_3',\n",
       " 'kmeans_g_4',\n",
       " 'kmeans_g_5',\n",
       " 'kmeans_g_6',\n",
       " 'kmeans_c_0',\n",
       " 'kmeans_c_1',\n",
       " 'kmeans_c_2',\n",
       " 'kmeans_c_3',\n",
       " 'kmeans_c_4',\n",
       " 'kmeans_c_5',\n",
       " 'kmeans_c_6',\n",
       " 'cp_time_24',\n",
       " 'cp_time_48',\n",
       " 'cp_time_72',\n",
       " 'cp_dose_D1',\n",
       " 'cp_dose_D2']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols_ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T20:27:55.343264Z",
     "start_time": "2020-12-01T17:39:45.480623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 5 3 5 3 4 7 6 9 1 0 2 4 9 4 1 3 4 0 1]\n",
      "SEED=0 seed_fold=0 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.016005 auc_without:0.779\n",
      "          score_without_acum:0.016005 (0.016005, 0.000139) error:0.000139\n",
      "          auc_without_acum:0.779 (0.789130, 0.008520) error:0.009\n",
      "[7 5 3 5 3 4 7 6 9 1 0 2 4 9 4 1 3 4 0 1]\n",
      "SEED=1 seed_fold=0 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.016011 auc_without:0.778\n",
      "          score_without_acum:0.015753 (0.016008, 0.000141) error:0.000145\n",
      "          auc_without_acum:0.789 (0.787968, 0.006849) error:0.007\n",
      "[7 5 3 5 3 4 7 6 9 1 0 2 4 9 4 1 3 4 0 1]\n",
      "SEED=2 seed_fold=0 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.015979 auc_without:0.780\n",
      "          score_without_acum:0.015654 (0.015998, 0.000132) error:0.000135\n",
      "          auc_without_acum:0.794 (0.788834, 0.008062) error:0.008\n",
      "[7 5 3 5 3 4 7 6 9 1 0 2 4 9 4 1 3 4 0 1]\n",
      "SEED=3 seed_fold=0 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.015979 auc_without:0.777\n",
      "          score_without_acum:0.015604 (0.015993, 0.000141) error:0.000144\n",
      "          auc_without_acum:0.796 (0.788709, 0.008072) error:0.008\n",
      "[2 0 0 8 9 4 5 5 9 0 8 2 4 1 1 2 7 9 6 9]\n",
      "SEED=4 seed_fold=1 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.016021 auc_without:0.780\n",
      "          score_without_acum:0.015558 (0.015999, 0.000141) error:0.000145\n",
      "          auc_without_acum:0.800 (0.789047, 0.008402) error:0.009\n",
      "[2 0 0 8 9 4 5 5 9 0 8 2 4 1 1 2 7 9 6 9]\n",
      "SEED=5 seed_fold=1 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.016017 auc_without:0.779\n",
      "          score_without_acum:0.015535 (0.016002, 0.000142) error:0.000147\n",
      "          auc_without_acum:0.801 (0.788569, 0.008395) error:0.009\n",
      "[2 0 0 8 9 4 5 5 9 0 8 2 4 1 1 2 7 9 6 9]\n",
      "SEED=6 seed_fold=1 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.016005 auc_without:0.782\n",
      "          score_without_acum:0.015519 (0.016002, 0.000140) error:0.000144\n",
      "          auc_without_acum:0.802 (0.788996, 0.008629) error:0.009\n",
      "[2 0 0 8 9 4 5 5 9 0 8 2 4 1 1 2 7 9 6 9]\n",
      "SEED=7 seed_fold=1 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.015980 auc_without:0.773\n",
      "          score_without_acum:0.015505 (0.016000, 0.000136) error:0.000140\n",
      "          auc_without_acum:0.802 (0.788392, 0.008715) error:0.009\n",
      "[3 2 7 1 2 8 9 5 9 8 4 1 7 3 0 7 0 2 3 1]\n",
      "SEED=8 seed_fold=2 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.016005 auc_without:0.784\n",
      "          score_without_acum:0.015492 (0.016000, 0.000132) error:0.000129\n",
      "          auc_without_acum:0.804 (0.788948, 0.009492) error:0.010\n",
      "[3 2 7 1 2 8 9 5 9 8 4 1 7 3 0 7 0 2 3 1]\n",
      "SEED=9 seed_fold=2 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.015983 auc_without:0.782\n",
      "          score_without_acum:0.015481 (0.015998, 0.000130) error:0.000130\n",
      "          auc_without_acum:0.805 (0.788888, 0.009459) error:0.010\n",
      "[3 2 7 1 2 8 9 5 9 8 4 1 7 3 0 7 0 2 3 1]\n",
      "SEED=10 seed_fold=2 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.016016 auc_without:0.781\n",
      "          score_without_acum:0.015473 (0.016000, 0.000129) error:0.000131\n",
      "          auc_without_acum:0.805 (0.788914, 0.009532) error:0.010\n",
      "[3 2 7 1 2 8 9 5 9 8 4 1 7 3 0 7 0 2 3 1]\n",
      "SEED=11 seed_fold=2 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.015957 auc_without:0.782\n",
      "          score_without_acum:0.015465 (0.015997, 0.000129) error:0.000132\n",
      "          auc_without_acum:0.806 (0.789103, 0.009643) error:0.010\n",
      "[1 4 2 9 0 2 8 0 3 0 8 0 7 1 5 0 3 5 3 9]\n",
      "SEED=12 seed_fold=3 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.015999 auc_without:0.777\n",
      "          score_without_acum:0.015460 (0.015997, 0.000129) error:0.000134\n",
      "          auc_without_acum:0.806 (0.789047, 0.009532) error:0.009\n",
      "[1 4 2 9 0 2 8 0 3 0 8 0 7 1 5 0 3 5 3 9]\n",
      "SEED=13 seed_fold=3 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.015989 auc_without:0.779\n",
      "          score_without_acum:0.015455 (0.015996, 0.000130) error:0.000136\n",
      "          auc_without_acum:0.806 (0.788821, 0.009530) error:0.009\n",
      "[1 4 2 9 0 2 8 0 3 0 8 0 7 1 5 0 3 5 3 9]\n",
      "SEED=14 seed_fold=3 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.016046 auc_without:0.778\n",
      "          score_without_acum:0.015454 (0.015999, 0.000130) error:0.000134\n",
      "          auc_without_acum:0.806 (0.788817, 0.009393) error:0.009\n",
      "[1 4 2 9 0 2 8 0 3 0 8 0 7 1 5 0 3 5 3 9]\n",
      "SEED=15 seed_fold=3 hidden_size=256 drop1_feat=0.05\n",
      "          score_without:0.015991 auc_without:0.777\n",
      "          score_without_acum:0.015450 (0.015999, 0.000129) error:0.000132\n",
      "          auc_without_acum:0.806 (0.788646, 0.009288) error:0.009\n"
     ]
    }
   ],
   "source": [
    "folds_cp = folds.copy()\n",
    "feature_cols = feature_cols_ini.copy()\n",
    "NFOLDS = CFG.num_folds\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "hidden_size = 256\n",
    "res = []\n",
    "drop1_feat = 0.05\n",
    "drop2_feat = 0.05\n",
    "drop3_feat = 0.25\n",
    "\n",
    "#https://www.kaggle.com/felipebihaiek/torch-continued-from-auxiliary-targets-smoothing\n",
    "# EPOCHS = 200\n",
    "# BATCH_SIZE = 512\n",
    "# LEARNING_RATE = 2e-4\n",
    "# WEIGHT_DECAY = 2e-7\n",
    "# EARLY_STOPPING_STEPS = 10\n",
    "# EARLY_STOP = False\n",
    "\n",
    "# Averaging on multiple SEEDS and different FOLDS\n",
    "SEED = np.arange(16)\n",
    "oof_seed = np.zeros((len(folds), len(target_cols)))\n",
    "predictions = np.zeros((len(test_noctl), len(target_cols)))\n",
    "losses_list = []\n",
    "folds_stds = []\n",
    "scores_seed = []\n",
    "for seed in SEED:\n",
    "    seed_fold = seed // 4\n",
    "    seed_run = seed % 4\n",
    "    folds['kfold'] = calc_folds(seed_fold)\n",
    "    \n",
    "#     print(folds['kfold'].value_counts())\n",
    "    print(folds['kfold'].values[:20])\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed_fold, seed_run, display=0)\n",
    "    oof_seed += oof_ \n",
    "    predictions += predictions_\n",
    "    \n",
    "    # OBTAIN METRICS\n",
    "    # --------------\n",
    "    # Loop score\n",
    "    folds_cp[target_cols] = oof_\n",
    "    y_true = folds[target_cols].values \n",
    "    y_pred = folds_cp[target_cols].values \n",
    "    score_without = log_loss_multi(y_true, y_pred)\n",
    "    auc_without = mean_auc(y_true, y_pred)\n",
    "    \n",
    "    # Score acum\n",
    "    folds_cp[target_cols] = oof_seed / (seed+1)\n",
    "    y_true_acum = folds[target_cols].values \n",
    "    y_pred_acum = folds_cp[target_cols].values \n",
    "    score_without_acum = log_loss_multi(y_true_acum, y_pred_acum)\n",
    "    auc_without_acum = mean_auc(y_true_acum, y_pred_acum)\n",
    "    \n",
    "    losses_df = pd.DataFrame(losses_list)\n",
    "    folds_loss_mean = losses_df['val_loss'].mean()\n",
    "    folds_loss_std = losses_df['val_loss'].std()\n",
    "    folds_auc_mean = losses_df['auc_loss'].mean()\n",
    "    folds_auc_std = losses_df['auc_loss'].std()\n",
    "    folds_loss_std_mean = losses_df.groupby(['seed_fold','seed_run'])['val_loss'].std().groupby('seed_fold').mean().mean()\n",
    "    auc_std_mean = losses_df.groupby(['seed_fold','seed_run'])['auc_loss'].std().groupby('seed_fold').mean().mean()\n",
    "    \n",
    "    print(f\"SEED={seed} seed_fold={seed_fold} hidden_size={hidden_size} drop1_feat={drop1_feat}\\n\\\n",
    "          score_without:{score_without:.6f} auc_without:{auc_without:.3f}\\n\\\n",
    "          score_without_acum:{score_without_acum:.6f} ({folds_loss_mean:.6f}, {folds_loss_std:.6f}) error:{folds_loss_std_mean:.6f}\\n\\\n",
    "          auc_without_acum:{auc_without_acum:.3f} ({folds_auc_mean:.6f}, {folds_auc_std:.6f}) error:{auc_std_mean:.3f}\")\n",
    "              \n",
    "    scores_seed.append(dict(seed=seed, seed_fold=seed_fold, hidden_size=hidden_size, drop1_feat=drop1_feat, \n",
    "                            score_without=score_without, auc_without=auc_without,\n",
    "                            score_without_acum=score_without_acum, folds_loss_mean=folds_loss_mean, folds_loss_std=folds_loss_std, folds_loss_std_mean=folds_loss_std_mean,\n",
    "                            auc_without_acum=auc_without_acum, folds_auc_mean=folds_auc_mean, folds_auc_std=folds_auc_std, auc_std_mean=auc_std_mean))\n",
    "    \n",
    "    \n",
    "    # SUBMISSION\n",
    "    # ----------------\n",
    "    test_noctl_cp_acum = test_noctl.copy()\n",
    "    for col in target_cols:\n",
    "        test_noctl_cp_acum[col] = 0.0\n",
    "    test_noctl_cp_acum[target_cols] = predictions / (seed+1)\n",
    "    \n",
    "    # Submission acum\n",
    "    submission = sample_submission.drop(columns=target_cols)\\\n",
    "    .merge(test_noctl_cp_acum[['sig_id']+target_cols], on='sig_id', how='left')\\\n",
    "    .fillna(0.0).reset_index(drop=True)\n",
    "    # sub.to_csv('submission.csv', index=False)\n",
    "    name_sub = output_dir / f'submission_seed_fold{seed_fold}__score{score_without_acum:.6f}.csv'\n",
    "    submission.to_csv(name_sub, index=False)\n",
    "\n",
    "    # Keep results\n",
    "    scores_seed_df = pd.DataFrame(scores_seed)\n",
    "    losses_df.to_csv(output_dir / 'losses_df.csv')\n",
    "    scores_seed_df.to_csv(output_dir / 'scores_seed_df.csv')\n",
    "    with open(output_dir / f'ann_dataframes.pkl', 'wb') as file:\n",
    "        pickle.dump(folds_cp, file)\n",
    "        pickle.dump(test_noctl_cp_acum, file)\n",
    "        pickle.dump(y_true_acum, file)\n",
    "        pickle.dump(y_pred_acum, file)\n",
    "        pickle.dump(feature_cols, file)\n",
    "        pickle.dump(target_cols, file)\n",
    "        pickle.dump(losses_df, file)\n",
    "        pickle.dump(scores_seed_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T20:27:55.353198Z",
     "start_time": "2020-12-01T20:27:55.346511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T20:27:55.722391Z",
     "start_time": "2020-12-01T20:27:55.354722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>adrenergic_receptor_antagonist</th>\n",
       "      <th>akt_inhibitor</th>\n",
       "      <th>aldehyde_dehydrogenase_inhibitor</th>\n",
       "      <th>alk_inhibitor</th>\n",
       "      <th>ampk_activator</th>\n",
       "      <th>analgesic</th>\n",
       "      <th>androgen_receptor_agonist</th>\n",
       "      <th>androgen_receptor_antagonist</th>\n",
       "      <th>anesthetic_-_local</th>\n",
       "      <th>angiogenesis_inhibitor</th>\n",
       "      <th>angiotensin_receptor_antagonist</th>\n",
       "      <th>anti-inflammatory</th>\n",
       "      <th>antiarrhythmic</th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>anticonvulsant</th>\n",
       "      <th>antifungal</th>\n",
       "      <th>antihistamine</th>\n",
       "      <th>antimalarial</th>\n",
       "      <th>antioxidant</th>\n",
       "      <th>antiprotozoal</th>\n",
       "      <th>antiviral</th>\n",
       "      <th>apoptosis_stimulant</th>\n",
       "      <th>aromatase_inhibitor</th>\n",
       "      <th>atm_kinase_inhibitor</th>\n",
       "      <th>atp-sensitive_potassium_channel_antagonist</th>\n",
       "      <th>atp_synthase_inhibitor</th>\n",
       "      <th>atpase_inhibitor</th>\n",
       "      <th>atr_kinase_inhibitor</th>\n",
       "      <th>aurora_kinase_inhibitor</th>\n",
       "      <th>autotaxin_inhibitor</th>\n",
       "      <th>bacterial_30s_ribosomal_subunit_inhibitor</th>\n",
       "      <th>bacterial_50s_ribosomal_subunit_inhibitor</th>\n",
       "      <th>bacterial_antifolate</th>\n",
       "      <th>bacterial_cell_wall_synthesis_inhibitor</th>\n",
       "      <th>bacterial_dna_gyrase_inhibitor</th>\n",
       "      <th>bacterial_dna_inhibitor</th>\n",
       "      <th>bacterial_membrane_integrity_inhibitor</th>\n",
       "      <th>bcl_inhibitor</th>\n",
       "      <th>bcr-abl_inhibitor</th>\n",
       "      <th>benzodiazepine_receptor_agonist</th>\n",
       "      <th>beta_amyloid_inhibitor</th>\n",
       "      <th>bromodomain_inhibitor</th>\n",
       "      <th>btk_inhibitor</th>\n",
       "      <th>calcineurin_inhibitor</th>\n",
       "      <th>calcium_channel_blocker</th>\n",
       "      <th>cannabinoid_receptor_agonist</th>\n",
       "      <th>cannabinoid_receptor_antagonist</th>\n",
       "      <th>carbonic_anhydrase_inhibitor</th>\n",
       "      <th>casein_kinase_inhibitor</th>\n",
       "      <th>caspase_activator</th>\n",
       "      <th>catechol_o_methyltransferase_inhibitor</th>\n",
       "      <th>cc_chemokine_receptor_antagonist</th>\n",
       "      <th>cck_receptor_antagonist</th>\n",
       "      <th>cdk_inhibitor</th>\n",
       "      <th>chelating_agent</th>\n",
       "      <th>chk_inhibitor</th>\n",
       "      <th>chloride_channel_blocker</th>\n",
       "      <th>cholesterol_inhibitor</th>\n",
       "      <th>cholinergic_receptor_antagonist</th>\n",
       "      <th>coagulation_factor_inhibitor</th>\n",
       "      <th>corticosteroid_agonist</th>\n",
       "      <th>cyclooxygenase_inhibitor</th>\n",
       "      <th>cytochrome_p450_inhibitor</th>\n",
       "      <th>dihydrofolate_reductase_inhibitor</th>\n",
       "      <th>dipeptidyl_peptidase_inhibitor</th>\n",
       "      <th>diuretic</th>\n",
       "      <th>dna_alkylating_agent</th>\n",
       "      <th>dna_inhibitor</th>\n",
       "      <th>dopamine_receptor_agonist</th>\n",
       "      <th>dopamine_receptor_antagonist</th>\n",
       "      <th>egfr_inhibitor</th>\n",
       "      <th>elastase_inhibitor</th>\n",
       "      <th>erbb2_inhibitor</th>\n",
       "      <th>estrogen_receptor_agonist</th>\n",
       "      <th>estrogen_receptor_antagonist</th>\n",
       "      <th>faah_inhibitor</th>\n",
       "      <th>farnesyltransferase_inhibitor</th>\n",
       "      <th>fatty_acid_receptor_agonist</th>\n",
       "      <th>fgfr_inhibitor</th>\n",
       "      <th>flt3_inhibitor</th>\n",
       "      <th>focal_adhesion_kinase_inhibitor</th>\n",
       "      <th>free_radical_scavenger</th>\n",
       "      <th>fungal_squalene_epoxidase_inhibitor</th>\n",
       "      <th>gaba_receptor_agonist</th>\n",
       "      <th>gaba_receptor_antagonist</th>\n",
       "      <th>gamma_secretase_inhibitor</th>\n",
       "      <th>glucocorticoid_receptor_agonist</th>\n",
       "      <th>glutamate_inhibitor</th>\n",
       "      <th>glutamate_receptor_agonist</th>\n",
       "      <th>glutamate_receptor_antagonist</th>\n",
       "      <th>gonadotropin_receptor_agonist</th>\n",
       "      <th>gsk_inhibitor</th>\n",
       "      <th>hcv_inhibitor</th>\n",
       "      <th>hdac_inhibitor</th>\n",
       "      <th>histamine_receptor_agonist</th>\n",
       "      <th>histamine_receptor_antagonist</th>\n",
       "      <th>histone_lysine_demethylase_inhibitor</th>\n",
       "      <th>histone_lysine_methyltransferase_inhibitor</th>\n",
       "      <th>hiv_inhibitor</th>\n",
       "      <th>hmgcr_inhibitor</th>\n",
       "      <th>hsp_inhibitor</th>\n",
       "      <th>igf-1_inhibitor</th>\n",
       "      <th>ikk_inhibitor</th>\n",
       "      <th>imidazoline_receptor_agonist</th>\n",
       "      <th>immunosuppressant</th>\n",
       "      <th>insulin_secretagogue</th>\n",
       "      <th>insulin_sensitizer</th>\n",
       "      <th>integrin_inhibitor</th>\n",
       "      <th>jak_inhibitor</th>\n",
       "      <th>kit_inhibitor</th>\n",
       "      <th>laxative</th>\n",
       "      <th>leukotriene_inhibitor</th>\n",
       "      <th>leukotriene_receptor_antagonist</th>\n",
       "      <th>lipase_inhibitor</th>\n",
       "      <th>lipoxygenase_inhibitor</th>\n",
       "      <th>lxr_agonist</th>\n",
       "      <th>mdm_inhibitor</th>\n",
       "      <th>mek_inhibitor</th>\n",
       "      <th>membrane_integrity_inhibitor</th>\n",
       "      <th>mineralocorticoid_receptor_antagonist</th>\n",
       "      <th>monoacylglycerol_lipase_inhibitor</th>\n",
       "      <th>monoamine_oxidase_inhibitor</th>\n",
       "      <th>monopolar_spindle_1_kinase_inhibitor</th>\n",
       "      <th>mtor_inhibitor</th>\n",
       "      <th>mucolytic_agent</th>\n",
       "      <th>neuropeptide_receptor_antagonist</th>\n",
       "      <th>nfkb_inhibitor</th>\n",
       "      <th>nicotinic_receptor_agonist</th>\n",
       "      <th>nitric_oxide_donor</th>\n",
       "      <th>nitric_oxide_production_inhibitor</th>\n",
       "      <th>nitric_oxide_synthase_inhibitor</th>\n",
       "      <th>norepinephrine_reuptake_inhibitor</th>\n",
       "      <th>nrf2_activator</th>\n",
       "      <th>opioid_receptor_agonist</th>\n",
       "      <th>opioid_receptor_antagonist</th>\n",
       "      <th>orexin_receptor_antagonist</th>\n",
       "      <th>p38_mapk_inhibitor</th>\n",
       "      <th>p-glycoprotein_inhibitor</th>\n",
       "      <th>parp_inhibitor</th>\n",
       "      <th>pdgfr_inhibitor</th>\n",
       "      <th>pdk_inhibitor</th>\n",
       "      <th>phosphodiesterase_inhibitor</th>\n",
       "      <th>phospholipase_inhibitor</th>\n",
       "      <th>pi3k_inhibitor</th>\n",
       "      <th>pkc_inhibitor</th>\n",
       "      <th>potassium_channel_activator</th>\n",
       "      <th>potassium_channel_antagonist</th>\n",
       "      <th>ppar_receptor_agonist</th>\n",
       "      <th>ppar_receptor_antagonist</th>\n",
       "      <th>progesterone_receptor_agonist</th>\n",
       "      <th>progesterone_receptor_antagonist</th>\n",
       "      <th>prostaglandin_inhibitor</th>\n",
       "      <th>prostanoid_receptor_antagonist</th>\n",
       "      <th>proteasome_inhibitor</th>\n",
       "      <th>protein_kinase_inhibitor</th>\n",
       "      <th>protein_phosphatase_inhibitor</th>\n",
       "      <th>protein_synthesis_inhibitor</th>\n",
       "      <th>protein_tyrosine_kinase_inhibitor</th>\n",
       "      <th>radiopaque_medium</th>\n",
       "      <th>raf_inhibitor</th>\n",
       "      <th>ras_gtpase_inhibitor</th>\n",
       "      <th>retinoid_receptor_agonist</th>\n",
       "      <th>retinoid_receptor_antagonist</th>\n",
       "      <th>rho_associated_kinase_inhibitor</th>\n",
       "      <th>ribonucleoside_reductase_inhibitor</th>\n",
       "      <th>rna_polymerase_inhibitor</th>\n",
       "      <th>serotonin_receptor_agonist</th>\n",
       "      <th>serotonin_receptor_antagonist</th>\n",
       "      <th>serotonin_reuptake_inhibitor</th>\n",
       "      <th>sigma_receptor_agonist</th>\n",
       "      <th>sigma_receptor_antagonist</th>\n",
       "      <th>smoothened_receptor_antagonist</th>\n",
       "      <th>sodium_channel_inhibitor</th>\n",
       "      <th>sphingosine_receptor_agonist</th>\n",
       "      <th>src_inhibitor</th>\n",
       "      <th>steroid</th>\n",
       "      <th>syk_inhibitor</th>\n",
       "      <th>tachykinin_antagonist</th>\n",
       "      <th>tgf-beta_receptor_inhibitor</th>\n",
       "      <th>thrombin_inhibitor</th>\n",
       "      <th>thymidylate_synthase_inhibitor</th>\n",
       "      <th>tlr_agonist</th>\n",
       "      <th>tlr_antagonist</th>\n",
       "      <th>tnf_inhibitor</th>\n",
       "      <th>topoisomerase_inhibitor</th>\n",
       "      <th>transient_receptor_potential_channel_antagonist</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.019252</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.009674</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.016150</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.006960</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.050058</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.021784</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.024022</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.007675</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.005056</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.018113</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.010997</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.015645</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.008537</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.005793</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.016471</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.036872</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.021532</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.069350</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.031443</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.010536</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.002407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.016710</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.020779</td>\n",
       "      <td>0.038668</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>0.008359</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.036928</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005593</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.014331</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.020687</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>0.050491</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.013168</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.033492</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.007354</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.003162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.011489</td>\n",
       "      <td>0.010413</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.016373</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.013215</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.012599</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.001743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.000775                0.001406   \n",
       "1  id_001897cda                     0.000209                0.000472   \n",
       "2  id_002429b5b                     0.000000                0.000000   \n",
       "3  id_00276f245                     0.000876                0.000915   \n",
       "4  id_0027f1083                     0.001436                0.001346   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.002783                        0.010936   \n",
       "1        0.002098                        0.002472   \n",
       "2        0.000000                        0.000000   \n",
       "3        0.001585                        0.011575   \n",
       "4        0.001998                        0.011489   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.019252                        0.005452   \n",
       "1                           0.000828                        0.000901   \n",
       "2                           0.000000                        0.000000   \n",
       "3                           0.016710                        0.004705   \n",
       "4                           0.010413                        0.002685   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.001537                       0.008184   \n",
       "1                    0.003150                       0.007858   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.004109                       0.003658   \n",
       "4                    0.005827                       0.001645   \n",
       "\n",
       "   adenylyl_cyclase_activator  adrenergic_receptor_agonist  \\\n",
       "0                    0.000201                     0.009429   \n",
       "1                    0.006541                     0.001923   \n",
       "2                    0.000000                     0.000000   \n",
       "3                    0.000271                     0.020779   \n",
       "4                    0.000553                     0.008985   \n",
       "\n",
       "   adrenergic_receptor_antagonist  akt_inhibitor  \\\n",
       "0                        0.009674       0.000315   \n",
       "1                        0.004694       0.002248   \n",
       "2                        0.000000       0.000000   \n",
       "3                        0.038668       0.001992   \n",
       "4                        0.016373       0.002150   \n",
       "\n",
       "   aldehyde_dehydrogenase_inhibitor  alk_inhibitor  ampk_activator  analgesic  \\\n",
       "0                          0.000626       0.000315        0.000776   0.000774   \n",
       "1                          0.000230       0.005793        0.000443   0.000340   \n",
       "2                          0.000000       0.000000        0.000000   0.000000   \n",
       "3                          0.000355       0.003359        0.001187   0.001950   \n",
       "4                          0.000248       0.000950        0.001273   0.001466   \n",
       "\n",
       "   androgen_receptor_agonist  androgen_receptor_antagonist  \\\n",
       "0                   0.002002                      0.007106   \n",
       "1                   0.000489                      0.001151   \n",
       "2                   0.000000                      0.000000   \n",
       "3                   0.002362                      0.004486   \n",
       "4                   0.002783                      0.003534   \n",
       "\n",
       "   anesthetic_-_local  angiogenesis_inhibitor  \\\n",
       "0            0.008737                0.002411   \n",
       "1            0.000794                0.002553   \n",
       "2            0.000000                0.000000   \n",
       "3            0.004449                0.001798   \n",
       "4            0.001560                0.001447   \n",
       "\n",
       "   angiotensin_receptor_antagonist  anti-inflammatory  antiarrhythmic  \\\n",
       "0                         0.001974           0.003753        0.000378   \n",
       "1                         0.004077           0.002053        0.000231   \n",
       "2                         0.000000           0.000000        0.000000   \n",
       "3                         0.002602           0.001486        0.000724   \n",
       "4                         0.005483           0.004895        0.000537   \n",
       "\n",
       "   antibiotic  anticonvulsant  antifungal  antihistamine  antimalarial  \\\n",
       "0    0.001916        0.000339    0.000745       0.000669      0.001153   \n",
       "1    0.000875        0.000335    0.000908       0.000445      0.000294   \n",
       "2    0.000000        0.000000    0.000000       0.000000      0.000000   \n",
       "3    0.003209        0.001815    0.001021       0.001227      0.002448   \n",
       "4    0.003189        0.000796    0.000758       0.000776      0.001121   \n",
       "\n",
       "   antioxidant  antiprotozoal  antiviral  apoptosis_stimulant  \\\n",
       "0     0.002862       0.001544   0.000625             0.005280   \n",
       "1     0.001292       0.001101   0.000463             0.002186   \n",
       "2     0.000000       0.000000   0.000000             0.000000   \n",
       "3     0.009186       0.003067   0.002157             0.001843   \n",
       "4     0.007426       0.003373   0.001684             0.004881   \n",
       "\n",
       "   aromatase_inhibitor  atm_kinase_inhibitor  \\\n",
       "0             0.005528              0.000169   \n",
       "1             0.000798              0.001180   \n",
       "2             0.000000              0.000000   \n",
       "3             0.002569              0.000849   \n",
       "4             0.003035              0.000481   \n",
       "\n",
       "   atp-sensitive_potassium_channel_antagonist  atp_synthase_inhibitor  \\\n",
       "0                                    0.000219                0.000701   \n",
       "1                                    0.000190                0.000203   \n",
       "2                                    0.000000                0.000000   \n",
       "3                                    0.000352                0.000425   \n",
       "4                                    0.000268                0.000466   \n",
       "\n",
       "   atpase_inhibitor  atr_kinase_inhibitor  aurora_kinase_inhibitor  \\\n",
       "0          0.005031              0.000222                 0.000369   \n",
       "1          0.002161              0.002766                 0.002118   \n",
       "2          0.000000              0.000000                 0.000000   \n",
       "3          0.002452              0.000550                 0.000672   \n",
       "4          0.001993              0.000506                 0.000505   \n",
       "\n",
       "   autotaxin_inhibitor  bacterial_30s_ribosomal_subunit_inhibitor  \\\n",
       "0             0.000285                                   0.004416   \n",
       "1             0.001572                                   0.000890   \n",
       "2             0.000000                                   0.000000   \n",
       "3             0.000688                                   0.004082   \n",
       "4             0.000641                                   0.009523   \n",
       "\n",
       "   bacterial_50s_ribosomal_subunit_inhibitor  bacterial_antifolate  \\\n",
       "0                                   0.010636              0.001390   \n",
       "1                                   0.000821              0.000164   \n",
       "2                                   0.000000              0.000000   \n",
       "3                                   0.007078              0.003061   \n",
       "4                                   0.010171              0.002148   \n",
       "\n",
       "   bacterial_cell_wall_synthesis_inhibitor  bacterial_dna_gyrase_inhibitor  \\\n",
       "0                                 0.005596                        0.007907   \n",
       "1                                 0.001977                        0.000537   \n",
       "2                                 0.000000                        0.000000   \n",
       "3                                 0.014367                        0.008359   \n",
       "4                                 0.012868                        0.009313   \n",
       "\n",
       "   bacterial_dna_inhibitor  bacterial_membrane_integrity_inhibitor  \\\n",
       "0                 0.006723                                0.000615   \n",
       "1                 0.001494                                0.000322   \n",
       "2                 0.000000                                0.000000   \n",
       "3                 0.007503                                0.000660   \n",
       "4                 0.008799                                0.000503   \n",
       "\n",
       "   bcl_inhibitor  bcr-abl_inhibitor  benzodiazepine_receptor_agonist  \\\n",
       "0       0.003686           0.000452                         0.002893   \n",
       "1       0.000748           0.000829                         0.004465   \n",
       "2       0.000000           0.000000                         0.000000   \n",
       "3       0.000701           0.000666                         0.003079   \n",
       "4       0.002741           0.000568                         0.003435   \n",
       "\n",
       "   beta_amyloid_inhibitor  bromodomain_inhibitor  btk_inhibitor  \\\n",
       "0                0.001496               0.003216       0.000345   \n",
       "1                0.001045               0.004152       0.016471   \n",
       "2                0.000000               0.000000       0.000000   \n",
       "3                0.001879               0.000410       0.001031   \n",
       "4                0.002026               0.001123       0.000970   \n",
       "\n",
       "   calcineurin_inhibitor  calcium_channel_blocker  \\\n",
       "0               0.000465                 0.016150   \n",
       "1               0.000166                 0.004350   \n",
       "2               0.000000                 0.000000   \n",
       "3               0.001091                 0.036928   \n",
       "4               0.000640                 0.005799   \n",
       "\n",
       "   cannabinoid_receptor_agonist  cannabinoid_receptor_antagonist  \\\n",
       "0                      0.001411                         0.001375   \n",
       "1                      0.004102                         0.003935   \n",
       "2                      0.000000                         0.000000   \n",
       "3                      0.001824                         0.005512   \n",
       "4                      0.001932                         0.002456   \n",
       "\n",
       "   carbonic_anhydrase_inhibitor  casein_kinase_inhibitor  caspase_activator  \\\n",
       "0                      0.001793                 0.001192           0.002638   \n",
       "1                      0.000923                 0.002822           0.000484   \n",
       "2                      0.000000                 0.000000           0.000000   \n",
       "3                      0.002246                 0.002199           0.001132   \n",
       "4                      0.002419                 0.002754           0.001249   \n",
       "\n",
       "   catechol_o_methyltransferase_inhibitor  cc_chemokine_receptor_antagonist  \\\n",
       "0                                0.001277                          0.006486   \n",
       "1                                0.000439                          0.003897   \n",
       "2                                0.000000                          0.000000   \n",
       "3                                0.001563                          0.006502   \n",
       "4                                0.001015                          0.004887   \n",
       "\n",
       "   cck_receptor_antagonist  cdk_inhibitor  chelating_agent  chk_inhibitor  \\\n",
       "0                 0.001596       0.000245         0.004463       0.000314   \n",
       "1                 0.000462       0.003911         0.001096       0.001884   \n",
       "2                 0.000000       0.000000         0.000000       0.000000   \n",
       "3                 0.001021       0.000893         0.002348       0.000366   \n",
       "4                 0.001483       0.001665         0.004043       0.000415   \n",
       "\n",
       "   chloride_channel_blocker  cholesterol_inhibitor  \\\n",
       "0                  0.001723               0.003257   \n",
       "1                  0.000695               0.002622   \n",
       "2                  0.000000               0.000000   \n",
       "3                  0.005593               0.004255   \n",
       "4                  0.006577               0.002565   \n",
       "\n",
       "   cholinergic_receptor_antagonist  coagulation_factor_inhibitor  \\\n",
       "0                         0.006960                      0.000412   \n",
       "1                         0.000421                      0.000276   \n",
       "2                         0.000000                      0.000000   \n",
       "3                         0.002944                      0.000673   \n",
       "4                         0.002090                      0.000494   \n",
       "\n",
       "   corticosteroid_agonist  cyclooxygenase_inhibitor  \\\n",
       "0                0.000963                  0.050058   \n",
       "1                0.000517                  0.004630   \n",
       "2                0.000000                  0.000000   \n",
       "3                0.000662                  0.014331   \n",
       "4                0.000774                  0.013215   \n",
       "\n",
       "   cytochrome_p450_inhibitor  dihydrofolate_reductase_inhibitor  \\\n",
       "0                   0.004881                           0.000630   \n",
       "1                   0.001573                           0.000511   \n",
       "2                   0.000000                           0.000000   \n",
       "3                   0.004868                           0.001652   \n",
       "4                   0.005654                           0.001600   \n",
       "\n",
       "   dipeptidyl_peptidase_inhibitor  diuretic  dna_alkylating_agent  \\\n",
       "0                        0.003538  0.000464              0.003083   \n",
       "1                        0.000940  0.000201              0.000689   \n",
       "2                        0.000000  0.000000              0.000000   \n",
       "3                        0.001078  0.000479              0.003161   \n",
       "4                        0.001568  0.000586              0.005436   \n",
       "\n",
       "   dna_inhibitor  dopamine_receptor_agonist  dopamine_receptor_antagonist  \\\n",
       "0       0.012156                   0.007091                      0.011411   \n",
       "1       0.000989                   0.000818                      0.000675   \n",
       "2       0.000000                   0.000000                      0.000000   \n",
       "3       0.020687                   0.013864                      0.050491   \n",
       "4       0.028674                   0.004092                      0.004553   \n",
       "\n",
       "   egfr_inhibitor  elastase_inhibitor  erbb2_inhibitor  \\\n",
       "0        0.000318            0.000790         0.000204   \n",
       "1        0.000575            0.000365         0.000279   \n",
       "2        0.000000            0.000000         0.000000   \n",
       "3        0.009901            0.000542         0.000389   \n",
       "4        0.000685            0.000374         0.000264   \n",
       "\n",
       "   estrogen_receptor_agonist  estrogen_receptor_antagonist  faah_inhibitor  \\\n",
       "0                   0.023328                      0.001263        0.004606   \n",
       "1                   0.002949                      0.002682        0.005519   \n",
       "2                   0.000000                      0.000000        0.000000   \n",
       "3                   0.004394                      0.003012        0.001047   \n",
       "4                   0.011757                      0.001679        0.001443   \n",
       "\n",
       "   farnesyltransferase_inhibitor  fatty_acid_receptor_agonist  fgfr_inhibitor  \\\n",
       "0                       0.000385                     0.001032        0.000405   \n",
       "1                       0.000201                     0.002160        0.005584   \n",
       "2                       0.000000                     0.000000        0.000000   \n",
       "3                       0.000832                     0.001115        0.001811   \n",
       "4                       0.000482                     0.002187        0.001515   \n",
       "\n",
       "   flt3_inhibitor  focal_adhesion_kinase_inhibitor  free_radical_scavenger  \\\n",
       "0        0.000202                         0.000572                0.001340   \n",
       "1        0.002903                         0.000343                0.000388   \n",
       "2        0.000000                         0.000000                0.000000   \n",
       "3        0.000697                         0.000383                0.000980   \n",
       "4        0.000955                         0.000218                0.000983   \n",
       "\n",
       "   fungal_squalene_epoxidase_inhibitor  gaba_receptor_agonist  \\\n",
       "0                             0.001905               0.022356   \n",
       "1                             0.000664               0.001404   \n",
       "2                             0.000000               0.000000   \n",
       "3                             0.001187               0.003632   \n",
       "4                             0.000526               0.005534   \n",
       "\n",
       "   gaba_receptor_antagonist  gamma_secretase_inhibitor  \\\n",
       "0                  0.021784                   0.001053   \n",
       "1                  0.003121                   0.002216   \n",
       "2                  0.000000                   0.000000   \n",
       "3                  0.005138                   0.000802   \n",
       "4                  0.004243                   0.000291   \n",
       "\n",
       "   glucocorticoid_receptor_agonist  glutamate_inhibitor  \\\n",
       "0                         0.001564             0.000946   \n",
       "1                         0.000989             0.001125   \n",
       "2                         0.000000             0.000000   \n",
       "3                         0.000586             0.001158   \n",
       "4                         0.000660             0.002638   \n",
       "\n",
       "   glutamate_receptor_agonist  glutamate_receptor_antagonist  \\\n",
       "0                    0.006984                       0.024022   \n",
       "1                    0.000683                       0.004588   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.004514                       0.013168   \n",
       "4                    0.002981                       0.016601   \n",
       "\n",
       "   gonadotropin_receptor_agonist  gsk_inhibitor  hcv_inhibitor  \\\n",
       "0                       0.001380       0.000551       0.006440   \n",
       "1                       0.000720       0.003653       0.003519   \n",
       "2                       0.000000       0.000000       0.000000   \n",
       "3                       0.001487       0.000766       0.003477   \n",
       "4                       0.001501       0.000566       0.004794   \n",
       "\n",
       "   hdac_inhibitor  histamine_receptor_agonist  histamine_receptor_antagonist  \\\n",
       "0        0.001412                    0.005356                       0.007675   \n",
       "1        0.000803                    0.000348                       0.001663   \n",
       "2        0.000000                    0.000000                       0.000000   \n",
       "3        0.000702                    0.002470                       0.033492   \n",
       "4        0.001317                    0.001778                       0.007974   \n",
       "\n",
       "   histone_lysine_demethylase_inhibitor  \\\n",
       "0                              0.000351   \n",
       "1                              0.000761   \n",
       "2                              0.000000   \n",
       "3                              0.001008   \n",
       "4                              0.000295   \n",
       "\n",
       "   histone_lysine_methyltransferase_inhibitor  hiv_inhibitor  hmgcr_inhibitor  \\\n",
       "0                                    0.000868       0.004824         0.000489   \n",
       "1                                    0.003261       0.000879         0.000445   \n",
       "2                                    0.000000       0.000000         0.000000   \n",
       "3                                    0.001533       0.006077         0.001758   \n",
       "4                                    0.001113       0.004063         0.000593   \n",
       "\n",
       "   hsp_inhibitor  igf-1_inhibitor  ikk_inhibitor  \\\n",
       "0       0.000488         0.000393       0.001439   \n",
       "1       0.000472         0.006707       0.001408   \n",
       "2       0.000000         0.000000       0.000000   \n",
       "3       0.000451         0.001328       0.000713   \n",
       "4       0.000856         0.000381       0.003778   \n",
       "\n",
       "   imidazoline_receptor_agonist  immunosuppressant  insulin_secretagogue  \\\n",
       "0                      0.002371           0.001710              0.001994   \n",
       "1                      0.000776           0.002119              0.002807   \n",
       "2                      0.000000           0.000000              0.000000   \n",
       "3                      0.002883           0.002391              0.001717   \n",
       "4                      0.001678           0.002105              0.002958   \n",
       "\n",
       "   insulin_sensitizer  integrin_inhibitor  jak_inhibitor  kit_inhibitor  \\\n",
       "0            0.000511            0.002810       0.000475       0.000237   \n",
       "1            0.036872            0.007646       0.003417       0.000968   \n",
       "2            0.000000            0.000000       0.000000       0.000000   \n",
       "3            0.000965            0.001264       0.000353       0.000689   \n",
       "4            0.005539            0.001965       0.000855       0.000683   \n",
       "\n",
       "   laxative  leukotriene_inhibitor  leukotriene_receptor_antagonist  \\\n",
       "0  0.000529               0.000533                         0.005056   \n",
       "1  0.000248               0.000232                         0.003518   \n",
       "2  0.000000               0.000000                         0.000000   \n",
       "3  0.000652               0.000798                         0.001845   \n",
       "4  0.000661               0.000650                         0.002086   \n",
       "\n",
       "   lipase_inhibitor  lipoxygenase_inhibitor  lxr_agonist  mdm_inhibitor  \\\n",
       "0          0.000989                0.003871     0.000714       0.000432   \n",
       "1          0.000926                0.002565     0.000302       0.000484   \n",
       "2          0.000000                0.000000     0.000000       0.000000   \n",
       "3          0.000865                0.002305     0.001058       0.000354   \n",
       "4          0.000904                0.002341     0.000385       0.000365   \n",
       "\n",
       "   mek_inhibitor  membrane_integrity_inhibitor  \\\n",
       "0       0.000335                      0.006368   \n",
       "1       0.001248                      0.001142   \n",
       "2       0.000000                      0.000000   \n",
       "3       0.000711                      0.005039   \n",
       "4       0.000556                      0.007212   \n",
       "\n",
       "   mineralocorticoid_receptor_antagonist  monoacylglycerol_lipase_inhibitor  \\\n",
       "0                               0.002198                           0.001545   \n",
       "1                               0.000763                           0.000305   \n",
       "2                               0.000000                           0.000000   \n",
       "3                               0.002606                           0.000663   \n",
       "4                               0.001254                           0.000746   \n",
       "\n",
       "   monoamine_oxidase_inhibitor  monopolar_spindle_1_kinase_inhibitor  \\\n",
       "0                     0.004429                              0.000513   \n",
       "1                     0.000907                              0.000618   \n",
       "2                     0.000000                              0.000000   \n",
       "3                     0.007939                              0.000722   \n",
       "4                     0.003568                              0.000457   \n",
       "\n",
       "   mtor_inhibitor  mucolytic_agent  neuropeptide_receptor_antagonist  \\\n",
       "0        0.000538         0.004917                          0.000420   \n",
       "1        0.002264         0.000430                          0.001139   \n",
       "2        0.000000         0.000000                          0.000000   \n",
       "3        0.001632         0.002943                          0.003598   \n",
       "4        0.002310         0.002950                          0.001188   \n",
       "\n",
       "   nfkb_inhibitor  nicotinic_receptor_agonist  nitric_oxide_donor  \\\n",
       "0        0.007559                    0.000707            0.001012   \n",
       "1        0.000785                    0.000241            0.000323   \n",
       "2        0.000000                    0.000000            0.000000   \n",
       "3        0.004345                    0.000564            0.002439   \n",
       "4        0.005055                    0.000506            0.002672   \n",
       "\n",
       "   nitric_oxide_production_inhibitor  nitric_oxide_synthase_inhibitor  \\\n",
       "0                           0.000887                         0.000958   \n",
       "1                           0.000534                         0.000289   \n",
       "2                           0.000000                         0.000000   \n",
       "3                           0.000667                         0.002606   \n",
       "4                           0.001154                         0.001335   \n",
       "\n",
       "   norepinephrine_reuptake_inhibitor  nrf2_activator  opioid_receptor_agonist  \\\n",
       "0                           0.000413        0.001107                 0.001842   \n",
       "1                           0.000196        0.000472                 0.000675   \n",
       "2                           0.000000        0.000000                 0.000000   \n",
       "3                           0.000889        0.000416                 0.006616   \n",
       "4                           0.000484        0.000898                 0.002750   \n",
       "\n",
       "   opioid_receptor_antagonist  orexin_receptor_antagonist  p38_mapk_inhibitor  \\\n",
       "0                    0.005153                    0.001155            0.000397   \n",
       "1                    0.001227                    0.000837            0.000504   \n",
       "2                    0.000000                    0.000000            0.000000   \n",
       "3                    0.009551                    0.003385            0.005239   \n",
       "4                    0.004163                    0.003469            0.001005   \n",
       "\n",
       "   p-glycoprotein_inhibitor  parp_inhibitor  pdgfr_inhibitor  pdk_inhibitor  \\\n",
       "0                  0.000696        0.001795         0.000195       0.000992   \n",
       "1                  0.003804        0.004107         0.001718       0.001254   \n",
       "2                  0.000000        0.000000         0.000000       0.000000   \n",
       "3                  0.000999        0.001177         0.000696       0.000689   \n",
       "4                  0.001147        0.001956         0.001151       0.000868   \n",
       "\n",
       "   phosphodiesterase_inhibitor  phospholipase_inhibitor  pi3k_inhibitor  \\\n",
       "0                     0.018113                 0.002315        0.001009   \n",
       "1                     0.021532                 0.000298        0.011179   \n",
       "2                     0.000000                 0.000000        0.000000   \n",
       "3                     0.006278                 0.001861        0.004548   \n",
       "4                     0.011003                 0.000908        0.002081   \n",
       "\n",
       "   pkc_inhibitor  potassium_channel_activator  potassium_channel_antagonist  \\\n",
       "0       0.000909                     0.001895                      0.010997   \n",
       "1       0.002777                     0.002252                      0.001125   \n",
       "2       0.000000                     0.000000                      0.000000   \n",
       "3       0.002481                     0.003525                      0.007354   \n",
       "4       0.001129                     0.006667                      0.002406   \n",
       "\n",
       "   ppar_receptor_agonist  ppar_receptor_antagonist  \\\n",
       "0               0.001346                  0.002060   \n",
       "1               0.069350                  0.019144   \n",
       "2               0.000000                  0.000000   \n",
       "3               0.000893                  0.001197   \n",
       "4               0.012599                  0.001789   \n",
       "\n",
       "   progesterone_receptor_agonist  progesterone_receptor_antagonist  \\\n",
       "0                       0.015645                          0.001363   \n",
       "1                       0.001472                          0.031443   \n",
       "2                       0.000000                          0.000000   \n",
       "3                       0.001653                          0.000746   \n",
       "4                       0.004508                          0.001986   \n",
       "\n",
       "   prostaglandin_inhibitor  prostanoid_receptor_antagonist  \\\n",
       "0                 0.004633                        0.008537   \n",
       "1                 0.000974                        0.002115   \n",
       "2                 0.000000                        0.000000   \n",
       "3                 0.002398                        0.003265   \n",
       "4                 0.003750                        0.003334   \n",
       "\n",
       "   proteasome_inhibitor  protein_kinase_inhibitor  \\\n",
       "0              0.000563                  0.003619   \n",
       "1              0.000313                  0.001807   \n",
       "2              0.000000                  0.000000   \n",
       "3              0.000725                  0.001953   \n",
       "4              0.000743                  0.002018   \n",
       "\n",
       "   protein_phosphatase_inhibitor  protein_synthesis_inhibitor  \\\n",
       "0                       0.000283                     0.002524   \n",
       "1                       0.000449                     0.000463   \n",
       "2                       0.000000                     0.000000   \n",
       "3                       0.000569                     0.008140   \n",
       "4                       0.000855                     0.004990   \n",
       "\n",
       "   protein_tyrosine_kinase_inhibitor  radiopaque_medium  raf_inhibitor  \\\n",
       "0                           0.000616           0.004038       0.000561   \n",
       "1                           0.000936           0.000407       0.000165   \n",
       "2                           0.000000           0.000000       0.000000   \n",
       "3                           0.001599           0.003400       0.000680   \n",
       "4                           0.001255           0.004715       0.001301   \n",
       "\n",
       "   ras_gtpase_inhibitor  retinoid_receptor_agonist  \\\n",
       "0              0.000671                   0.001950   \n",
       "1              0.000835                   0.000702   \n",
       "2              0.000000                   0.000000   \n",
       "3              0.001064                   0.000327   \n",
       "4              0.000544                   0.000663   \n",
       "\n",
       "   retinoid_receptor_antagonist  rho_associated_kinase_inhibitor  \\\n",
       "0                      0.000350                         0.000522   \n",
       "1                      0.001221                         0.032219   \n",
       "2                      0.000000                         0.000000   \n",
       "3                      0.000607                         0.001236   \n",
       "4                      0.001067                         0.002523   \n",
       "\n",
       "   ribonucleoside_reductase_inhibitor  rna_polymerase_inhibitor  \\\n",
       "0                            0.000711                  0.001746   \n",
       "1                            0.001157                  0.002160   \n",
       "2                            0.000000                  0.000000   \n",
       "3                            0.001199                  0.001050   \n",
       "4                            0.004046                  0.001690   \n",
       "\n",
       "   serotonin_receptor_agonist  serotonin_receptor_antagonist  \\\n",
       "0                    0.010386                       0.004980   \n",
       "1                    0.006146                       0.000639   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.015369                       0.031623   \n",
       "4                    0.007751                       0.007279   \n",
       "\n",
       "   serotonin_reuptake_inhibitor  sigma_receptor_agonist  \\\n",
       "0                      0.003979                0.003358   \n",
       "1                      0.000238                0.000574   \n",
       "2                      0.000000                0.000000   \n",
       "3                      0.003415                0.002741   \n",
       "4                      0.001716                0.001493   \n",
       "\n",
       "   sigma_receptor_antagonist  smoothened_receptor_antagonist  \\\n",
       "0                   0.001028                        0.000943   \n",
       "1                   0.000696                        0.003111   \n",
       "2                   0.000000                        0.000000   \n",
       "3                   0.004202                        0.001429   \n",
       "4                   0.000872                        0.002188   \n",
       "\n",
       "   sodium_channel_inhibitor  sphingosine_receptor_agonist  src_inhibitor  \\\n",
       "0                  0.024675                      0.002723       0.000424   \n",
       "1                  0.003955                      0.000478       0.010536   \n",
       "2                  0.000000                      0.000000       0.000000   \n",
       "3                  0.008800                      0.001605       0.001648   \n",
       "4                  0.015337                      0.002040       0.000748   \n",
       "\n",
       "    steroid  syk_inhibitor  tachykinin_antagonist  \\\n",
       "0  0.000411       0.000438               0.001061   \n",
       "1  0.000396       0.002270               0.002186   \n",
       "2  0.000000       0.000000               0.000000   \n",
       "3  0.000945       0.001106               0.003893   \n",
       "4  0.001140       0.001150               0.003335   \n",
       "\n",
       "   tgf-beta_receptor_inhibitor  thrombin_inhibitor  \\\n",
       "0                     0.000131            0.000586   \n",
       "1                     0.001463            0.000275   \n",
       "2                     0.000000            0.000000   \n",
       "3                     0.000697            0.001765   \n",
       "4                     0.000705            0.000762   \n",
       "\n",
       "   thymidylate_synthase_inhibitor  tlr_agonist  tlr_antagonist  tnf_inhibitor  \\\n",
       "0                        0.000749     0.001139        0.000628       0.003459   \n",
       "1                        0.000211     0.000577        0.000858       0.001744   \n",
       "2                        0.000000     0.000000        0.000000       0.000000   \n",
       "3                        0.002721     0.002140        0.000573       0.001408   \n",
       "4                        0.002467     0.001977        0.000633       0.001249   \n",
       "\n",
       "   topoisomerase_inhibitor  transient_receptor_potential_channel_antagonist  \\\n",
       "0                 0.000915                                         0.000865   \n",
       "1                 0.006828                                         0.000885   \n",
       "2                 0.000000                                         0.000000   \n",
       "3                 0.000982                                         0.001415   \n",
       "4                 0.003903                                         0.000684   \n",
       "\n",
       "   tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                               0.000645      0.002162         0.004678   \n",
       "1                               0.000581      0.000531         0.003826   \n",
       "2                               0.000000      0.000000         0.000000   \n",
       "3                               0.000510      0.000693         0.002439   \n",
       "4                               0.000682      0.000461         0.003579   \n",
       "\n",
       "   tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0           0.001068                   0.000489   \n",
       "1           0.000131                   0.007131   \n",
       "2           0.000000                   0.000000   \n",
       "3           0.006351                   0.003592   \n",
       "4           0.001143                   0.001253   \n",
       "\n",
       "   ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                               0.000534         0.000592   0.001493   \n",
       "1                               0.000211         0.006375   0.000659   \n",
       "2                               0.000000         0.000000   0.000000   \n",
       "3                               0.000569         0.001510   0.001875   \n",
       "4                               0.000534         0.001934   0.001592   \n",
       "\n",
       "   vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0.011096       0.000898  \n",
       "1                    0.001333       0.002407  \n",
       "2                    0.000000       0.000000  \n",
       "3                    0.000627       0.003162  \n",
       "4                    0.000245       0.001743  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(name_sub).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.997px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
